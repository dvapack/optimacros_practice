{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c9cf3b",
   "metadata": {},
   "source": [
    "В данном ноутбуке находятся примеры работы с классом Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0be0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, HuberRegressor, Lasso, \\\n",
    "                                RANSACRegressor, Ridge, TheilSenRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from statsmodels.tsa.api import Holt, SimpleExpSmoothing, ExponentialSmoothing, SARIMAX\n",
    "import statsmodels\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "\n",
    "from validation_system.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09033d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(x: pd.Series, weights_coeffs: list) -> pd.Series:\n",
    "    return (x * pd.Series(weights_coeffs, index=x.index)).sum() / len(x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2b1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_coefficients(ts: pd.Series, timestamps: pd.Series, time_step: str, timestamps_res: pd.DatetimeIndex) -> tuple[dict, pd.Series]:\n",
    "    \"\"\"\n",
    "    Вычисление сезонных коэффициентов на основе ряда.\n",
    "    :param ts: Временной ряд;\n",
    "    :param timestamps: Метка времени;\n",
    "    :param time_step: Шаг времени;\n",
    "    :param timestamps_res: Временные метки, для которых нужно получить коэффициенты\n",
    "    :return: Словарь с сезонными коэффициентами, временные метки\n",
    "    \"\"\"\n",
    "    mean_sales = np.mean(ts.values)\n",
    "    marks_res = None\n",
    "    marks = None\n",
    "    match time_step:\n",
    "        case 'YS':\n",
    "            marks = timestamps.dt.year\n",
    "            marks_res = timestamps_res.year\n",
    "        case 'QS':\n",
    "            marks = timestamps.dt.quarter\n",
    "            marks_res = timestamps_res.quarter\n",
    "        case 'MS':\n",
    "            marks = timestamps.dt.month\n",
    "            marks_res = timestamps_res.month\n",
    "        case 'W' | 'W-MON':\n",
    "            marks = (timestamps.dt.day - 1 + (\n",
    "                    timestamps - pd.to_timedelta(timestamps.dt.day - 1, unit='d')).dt.dayofweek) // 7 + 1\n",
    "            marks_res = (timestamps_res.day - 1 + (\n",
    "                    timestamps_res - pd.to_timedelta(timestamps_res.day - 1, unit='d')).dayofweek) // 7 + 1\n",
    "        case 'D':\n",
    "            marks = timestamps.dt.dayofweek\n",
    "            marks_res = timestamps_res.dayofweek\n",
    "    dict_seasonality = {}\n",
    "    df = pd.DataFrame({'ds': marks, 'y': ts})\n",
    "    for timestamp in marks.unique():\n",
    "        values = df[df.ds == timestamp].y\n",
    "        dict_seasonality[timestamp] = np.mean(values / mean_sales)\n",
    "    for timestamp in set(marks_res.unique()) - set(marks.unique()):\n",
    "        dict_seasonality[timestamp] = dict_seasonality.get(timestamp, 1)\n",
    "    return dict_seasonality, marks_res\n",
    "\n",
    "def calculate_weights_coeffs(n: int, weights_type: str, weights_coeffs: list) -> list:\n",
    "    \"\"\"\n",
    "    Вычисление коэффициента весов на основе заданного типа весов и количества элементов\n",
    "    :param n: Количество эламентов;\n",
    "    :param weights_type: Тип весов;\n",
    "    :param weights_coeffs: Изначальные коэффициенты весов;\n",
    "    :return: Коэффициенты весов\n",
    "    \"\"\"\n",
    "    if weights_type == 'custom':\n",
    "        return weights_coeffs\n",
    "    elif weights_type == 'new':\n",
    "        reverse = False\n",
    "    elif weights_type == 'old':\n",
    "        reverse = True\n",
    "    else:\n",
    "        logging.exception(f'Передан несуществующий режим \"{weights_type}\". '\n",
    "                          f'Необходимо выбирать режимы: \"new\", \"old\", \"custom\". '\n",
    "                          f'Для данного пересечения будет по умолчанию будет выбран метод \"new\".')\n",
    "        reverse = False\n",
    "    a1 = 0.001\n",
    "    d = (2 - 2 * a1 * n) / (n * (n - 1))\n",
    "    res = [a1 + d * i for i in range(0, n)]\n",
    "    res.sort(reverse=reverse)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b7163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const(ts: pd.Series, n_predict: int, type: str) -> tuple[pd.Series, float]:\n",
    "    \"\"\"\n",
    "    Прогноз - константа\n",
    "    :param ts: Временной ряд;\n",
    "    :param n_predict: Количество предсказаний;\n",
    "    :param type: Тип константы;\n",
    "    :return: Фрейм с предсказанием\n",
    "    \"\"\"\n",
    "    n = len(ts.index)\n",
    "    value = None\n",
    "    match (type):\n",
    "        case 'Moda':\n",
    "            value = ts.mode()[0]\n",
    "        case 'Mean':\n",
    "            value = ts.mean()\n",
    "        case 'Min':\n",
    "            value = ts.min()\n",
    "        case 'Max':\n",
    "            value = ts.max()\n",
    "        case 'Median':\n",
    "            value = ts.median()\n",
    "\n",
    "    ts_res = pd.Series(value, index=range(n + n_predict), dtype='float64')\n",
    "    return ts_res, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4395e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rol_mean_fit(timestamps: pd.Series, time_step: str, ts: pd.Series, n_predict: int, window_size: int,\n",
    "                 weights_coeffs: list, weights_type: str, sample: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Создает скользящее среднее, формирует список компонентов\n",
    "\n",
    "    :param ts: Временной ряд\n",
    "    :param n_predict: Количество периодов для прогнозирования\n",
    "    :param window_size: Размер окна\n",
    "    :param weights_coeffs: Весовые коэффциенты\n",
    "    :param weights_type: Тип весов\n",
    "    :param sample: Датафрейм с признаками (не используется);\n",
    "    :return: Прогноз\n",
    "    \"\"\"\n",
    "    weights_coeffs = calculate_weights_coeffs(window_size, weights_type, weights_coeffs)\n",
    "    ts_res = ts.copy()\n",
    "    ts_base = None\n",
    "    for i in range(n_predict):\n",
    "        ts_res[len(ts_res.index)] = np.nan\n",
    "        rol = ts_res.fillna(0).rolling(window_size)\n",
    "        if i == 0:\n",
    "            ts_base = rol.apply(lambda x: weighted_mean(x, weights_coeffs)).shift(1)[:-1]\n",
    "            ts_base[:window_size] = ts[:window_size].values\n",
    "        ts_res = ts_res.where(pd.notna, other=rol.apply(lambda x: weighted_mean(x, weights_coeffs)).shift(1))\n",
    "    ts_res.loc[ts_base.index] = ts_base.values\n",
    "    return ts_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9819c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def croston_tsb_fit(timestamps: pd.Series, ts: pd.Series, alpha: float, beta: float, n_predict: int,\n",
    "                    time_step: str, sample: pd.DataFrame) -> tuple[pd.Series, dict]:\n",
    "    \"\"\"\n",
    "    Прогноз - метод Кростона.\n",
    "    :param timestamps: Временные метки;\n",
    "    :param ts: Временной ряд;\n",
    "    :param alpha: Параметр сглаживания для уровня;\n",
    "    :param beta: Параметр сглаживания для вероятности;\n",
    "    :param n_predict: Количество предсказаний;\n",
    "    :param time_step: Шаг прогноза;\n",
    "    :param sample: Датафрейм с признаками (не используется);\n",
    "    :return: Фрейм с предсказанием\n",
    "    \"\"\"\n",
    "    d = np.array(ts)\n",
    "    cols = len(d)\n",
    "    d = np.append(d, [np.nan] * n_predict)\n",
    "\n",
    "    # Уровень(a), Вероятность(p), Прогноз(f)\n",
    "    a, p, f = np.full((3, cols + n_predict + 1), np.nan)\n",
    "\n",
    "    # Инициализация\n",
    "    first_occurrence = np.argmax(d[:cols] > 0)\n",
    "    a[0] = d[first_occurrence]\n",
    "    p[0] = 1 / (1 + first_occurrence)\n",
    "    f[0] = p[0] * a[0]\n",
    "\n",
    "    # Заполнение матриц уровня и вероятности, прогноз\n",
    "    for t in range(cols):\n",
    "        if d[t] > 0:\n",
    "            a[t + 1] = alpha * d[t] + (1 - alpha) * a[t]\n",
    "            p[t + 1] = beta * 1 + (1 - beta) * p[t]\n",
    "        else:\n",
    "            a[t + 1] = a[t]\n",
    "            p[t + 1] = (1 - beta) * p[t]\n",
    "        f[t + 1] = p[t + 1] * a[t + 1]\n",
    "    a[cols + 1:cols + n_predict + 1] = a[cols]\n",
    "    p[cols + 1:cols + n_predict + 1] = p[cols]\n",
    "    f[cols + 1:cols + n_predict + 1] = f[cols]\n",
    "\n",
    "    ts_res = pd.Series(index=range(cols + n_predict), dtype='float64')\n",
    "    ts_res.loc[ts_res.index] = f[1:]\n",
    "    timestamps_res = pd.date_range(start=timestamps.iloc[0], freq=time_step, periods=len(ts_res))\n",
    "    dict_seasonality, marks_res = seasonal_coefficients(ts, timestamps, time_step, timestamps_res)\n",
    "    df = pd.DataFrame({'y_pred': ts_res, 'indexes': marks_res})\n",
    "    df.loc[cols + 1:cols + n_predict + 1, 'y_pred'] = df.iloc[cols + 1:cols + n_predict + 1].apply(\n",
    "        lambda x: x.y_pred * dict_seasonality[x.indexes], axis=1)\n",
    "    return df.y_pred.reset_index(drop=True)  # , {'alpha': alpha, 'beta': beta}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51cf278",
   "metadata": {},
   "source": [
    "Пример загрузки данных от optimacros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46064614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['croston_tsb', 'elastic_net', 'exp_smoothing', 'holt', 'holt_winters', 'huber', 'lasso', 'polynomial', 'ransac', 'ridge', 'rol_mean', 'theil_sen', 'const', 'catboost', 'sarima', 'prophet', 'random_forest', 'symfit_fourier_fft']\n",
      "Hyperparams: [{'croston_tsb_min_alpha': 0, 'croston_tsb_max_alpha': 1, 'croston_tsb_min_beta': 0, 'croston_tsb_max_beta': 1, 'croston_tsb_step': 0.1}, {'elastic_net_min_alpha': 0, 'elastic_net_max_alpha': 1, 'elastic_net_max_l1': 1, 'elastic_net_min_l1': 0, 'elastic_net_step': 0.05}, {'exp_smoothing_min_alpha': 0, 'exp_smoothing_max_alpha': 1, 'exp_smoothing_step': 0.1}, {'holt_min_alpha': 0, 'holt_max_alpha': 1, 'holt_min_beta': 0, 'holt_max_beta': 1, 'holt_step': 0.1}, {'holt_winters_min_seasonality': 2, 'holt_winters_max_seasonality': 7, 'holt_winters_trend_types': ['add', 'mul', None], 'holt_winters_seasonal_types': ['add', 'mul', None]}, {'huber_min_degrees': 1, 'huber_max_degrees': 5}, {'lasso_min_alpha': 0, 'lasso_max_alpha': 1, 'lasso_step': 0.05}, {'polynomial_min_degrees': 2, 'polynomial_max_degrees': 5}, {'ransac_min_degrees': 1, 'ransac_max_degrees': 5}, {'ridge_min_alpha': 0, 'ridge_max_alpha': 1, 'ridge_step': 0.05}, {'rol_mean_min_window_size': 2, 'rol_mean_max_window_size': 10, 'rol_mean_weights_type': 'new', 'rol_mean_weights_coeffs': 2}, {'theil_sen_min_degrees': 1, 'theil_sen_max_degrees': 5}, {'type': 'Median'}, {'learning_rate': [0.075, 0.1, 0.3, 0.5], 'n_estimators': [1, 5, 10, 15, 20, 25, 30], 'depth': [1, 2, 4, 8, 10]}, {'min_p': 0, 'max_p': 1, 'min_d': 0, 'max_d': 1, 'min_q': 0, 'max_q': 1, 'min_P': 0, 'max_P': 1, 'min_D': 0, 'max_D': 1, 'min_Q': 0, 'max_Q': 1}, {'seasonality_mode': ['additive', 'multiplicative'], 'changepoint_prior_scale': [0.001, 0.5], 'seasonality_prior_scale': [0.1, 10.0]}, {'n_estimators': [1, 5, 10, 15, 20, 25, 30], 'max_features': [1.0, 'log2', 'sqrt'], 'max_depth': [1, 2, 4, 8, 10], 'min_samples_split': [2, 10, 20, 30], 'min_samples_leaf': [2, 10, 20, 30]}, {'min_components': 1, 'max_components': 9}]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\"om_correct.csv\")\n",
    "models, hyperparams = dataloader.load_hyperparams_from_optimacros()\n",
    "print(f\"Models: {models}\")\n",
    "print(f\"Hyperparams: {hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3080cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb6fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции генерации данных определены.\n",
      "Сгенерированы данные для регрессии: X_reg.shape=(100, 5), y_reg.shape=(100,)\n",
      "Сгенерированы данные для временных рядов: df_ts.shape=(100, 2)\n"
     ]
    }
   ],
   "source": [
    "def generate_regression_data(n_samples=100, n_features=5):\n",
    "    \"\"\"Генерирует фейковые данные для задач регрессии.\"\"\"\n",
    "    X = np.random.rand(n_samples, n_features) * 10\n",
    "    # Простое линейное отношение с шумом\n",
    "    true_coef = np.array([1.5, -0.8, 0.5, 2.1, -1.2][:n_features])\n",
    "    y = X @ true_coef + np.random.normal(0, 2, n_samples)\n",
    "    return pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(n_features)]), pd.Series(y, name='target')\n",
    "\n",
    "def generate_time_series_data(n_points=100, trend_strength=0.5, seasonality_period=12, seasonality_strength=5):\n",
    "    \"\"\"Генерирует фейковые данные временного ряда с трендом и сезонностью.\"\"\"\n",
    "    dates = pd.date_range(start='2020-01-01', periods=n_points, freq='MS')\n",
    "    time_index = np.arange(n_points)\n",
    "\n",
    "    # ТРЕНД\n",
    "    trend = trend_strength * time_index\n",
    "\n",
    "    # СЕЗОННОСТЬ\n",
    "    seasonality = seasonality_strength * np.sin(2 * np.pi * time_index / seasonality_period)\n",
    "\n",
    "    # ШУМ\n",
    "    noise = np.random.normal(0, 1.5, n_points)\n",
    "\n",
    "    # ОБЩИЙ РЯД\n",
    "    y = trend + seasonality + noise\n",
    "\n",
    "    df = pd.DataFrame({'ds': dates, 'y': y}) # 'ds' и 'y' - обязательные названия для Prophet\n",
    "    return df\n",
    "\n",
    "print(\"Функции генерации данных определены.\")\n",
    "\n",
    "# Генерируем данные для регрессии\n",
    "X_reg, y_reg = generate_regression_data()\n",
    "print(f\"Сгенерированы данные для регрессии: X_reg.shape={X_reg.shape}, y_reg.shape={y_reg.shape}\")\n",
    "\n",
    "# Генерируем данные для временных рядов\n",
    "df_ts = generate_time_series_data()\n",
    "print(f\"Сгенерированы данные для временных рядов: df_ts.shape={df_ts.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75501a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ElasticNet успешно обучена.\n",
      "  HuberRegressor успешно обучена.\n",
      "  Lasso успешно обучена.\n",
      "  RANSACRegressor успешно обучена.\n",
      "  Ridge успешно обучена.\n",
      "  TheilSenRegressor успешно обучена.\n",
      "  RandomForestRegressor успешно обучена.\n",
      "  CatBoostRegressor успешно обучена.\n",
      "  SimpleExpSmoothing успешно обучена.\n",
      "  Holt успешно обучена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ExponentialSmoothing успешно обучена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:48:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "13:48:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SARIMAX успешно обучена.\n",
      "  Prophet успешно обучена.\n"
     ]
    }
   ],
   "source": [
    "elastic_net = ElasticNet(random_state=42)\n",
    "try:\n",
    "    elastic_net.fit(X_reg, y_reg)\n",
    "    y_pred_en = elastic_net.predict(X_reg.head(5))\n",
    "    print(\"  ElasticNet успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении ElasticNet: {e}\")\n",
    "\n",
    "huber = HuberRegressor()\n",
    "try:\n",
    "    huber.fit(X_reg, y_reg)\n",
    "    y_pred_huber = huber.predict(X_reg.head(5))\n",
    "    print(\"  HuberRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении HuberRegressor: {e}\")\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "try:\n",
    "    lasso.fit(X_reg, y_reg)\n",
    "    y_pred_lasso = lasso.predict(X_reg.head(5))\n",
    "    print(\"  Lasso успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Lasso: {e}\")\n",
    "\n",
    "ransac = RANSACRegressor(random_state=42)\n",
    "try:\n",
    "    ransac.fit(X_reg, y_reg)\n",
    "    y_pred_ransac = ransac.predict(X_reg.head(5))\n",
    "    print(\"  RANSACRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении RANSACRegressor: {e}\")\n",
    "\n",
    "ridge = Ridge(random_state=42)\n",
    "try:\n",
    "    ridge.fit(X_reg, y_reg)\n",
    "    y_pred_ridge = ridge.predict(X_reg.head(5))\n",
    "    print(\"  Ridge успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Ridge: {e}\")\n",
    "\n",
    "theil_sen = TheilSenRegressor(random_state=42)\n",
    "try:\n",
    "    theil_sen.fit(X_reg, y_reg)\n",
    "    y_pred_theil_sen = theil_sen.predict(X_reg.head(5))\n",
    "    print(\"  TheilSenRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении TheilSenRegressor: {e}\")\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state=42, n_estimators=50)\n",
    "try:\n",
    "    random_forest.fit(X_reg, y_reg)\n",
    "    y_pred_rf = random_forest.predict(X_reg.head(5))\n",
    "    print(\"  RandomForestRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении RandomForestRegressor: {e}\")\n",
    "\n",
    "catboost = CatBoostRegressor(random_state=42, verbose=0, iterations=50)\n",
    "try:\n",
    "    catboost.fit(X_reg, y_reg)\n",
    "    y_pred_cat = catboost.predict(X_reg.head(5))\n",
    "    print(\"  CatBoostRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении CatBoostRegressor: {e}\")\n",
    "\n",
    "y_ts = df_ts.set_index('ds')['y']\n",
    "\n",
    "models_ts_statsmodels = {\n",
    "    \"SimpleExpSmoothing\": SimpleExpSmoothing(y_ts, initialization_method=\"estimated\"),\n",
    "    \"Holt\": Holt(y_ts, initialization_method=\"estimated\"),\n",
    "    \"ExponentialSmoothing\": ExponentialSmoothing(y_ts, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\")\n",
    "}\n",
    "\n",
    "simpexpsmoth = SimpleExpSmoothing(y_ts, initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_simpexpsmoth = simpexpsmoth.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_simpexpsmoth = model_fit_simpexpsmoth.forecast(forecast_steps)\n",
    "    print(\"  SimpleExpSmoothing успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении SimpleExpSmoothing: {e}\")\n",
    "\n",
    "holt = Holt(y_ts, initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_holt = holt.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_holt = model_fit_holt.forecast(forecast_steps)\n",
    "    print(\"  Holt успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Holt: {e}\")\n",
    "\n",
    "expsmoothing = ExponentialSmoothing(y_ts, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_expsmoothing = expsmoothing.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_expsmoothing = model_fit_expsmoothing.forecast(forecast_steps)\n",
    "    print(\"  ExponentialSmoothing успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении ExponentialSmoothing: {e}\")\n",
    "\n",
    "sarimax = SARIMAX(y_ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12), enforce_stationarity=False, enforce_invertibility=False)\n",
    "try:\n",
    "    model_fit_sarimax = sarimax.fit(disp=False)\n",
    "    forecast_steps = 5\n",
    "    forecast_sarimax = model_fit_sarimax.forecast(forecast_steps)\n",
    "    print(\"  SARIMAX успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении SARIMAX: {e}\")\n",
    "\n",
    "model_prophet = Prophet()\n",
    "try:\n",
    "    model_prophet.fit(df_ts)\n",
    "    future = model_prophet.make_future_dataframe(periods=5, freq='MS')\n",
    "    forecast_prophet = model_prophet.predict(future)\n",
    "    print(\"  Prophet успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Prophet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ee024",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc898f59",
   "metadata": {},
   "source": [
    "Пример получения гиперпараметров моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a563237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры модели ElasticNet: {'Model': 'elastic_net', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}}\n",
      "Гиперпараметры модели HuberRegressor: {'Model': 'huber', 'Params': {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}}\n",
      "Гиперпараметры модели Lasso: {'Model': 'elastic_net', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}}\n",
      "Гиперпараметры модели RANSACRegressor: {'Model': 'ransac', 'Params': {'estimator': None, 'is_data_valid': None, 'is_model_valid': None, 'loss': 'absolute_error', 'max_skips': inf, 'max_trials': 100, 'min_samples': None, 'random_state': 42, 'residual_threshold': None, 'stop_n_inliers': inf, 'stop_probability': 0.99, 'stop_score': inf}}\n",
      "Гиперпараметры модели Ridge: {'Model': 'ridge', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}}\n",
      "Гиперпараметры модели TheilSenRegressor: {'Model': 'theil_sen', 'Params': {'copy_X': 'deprecated', 'fit_intercept': True, 'max_iter': 300, 'max_subpopulation': 10000.0, 'n_jobs': None, 'n_subsamples': None, 'random_state': 42, 'tol': 0.001, 'verbose': False}}\n",
      "Гиперпараметры модели RandomForestRegressor: {'Model': 'random_forest', 'Params': {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}}\n",
      "Гиперпараметры модели CatBoostRegressor: {'Model': 'catboost', 'Params': {'iterations': 50, 'loss_function': 'RMSE', 'verbose': 0, 'random_state': 42}}\n",
      "Гиперпараметры модели SimpleExpSmoothing: {'Model': 'exp_smoothing', 'Params': {'smoothing_level': 0.9999999850988388, 'smoothing_trend': nan, 'smoothing_seasonal': nan, 'damping_trend': nan, 'initial_level': -0.549052936757062, 'initial_trend': nan, 'initial_seasons': array([], dtype=float64), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели Holt: {'Model': 'holt', 'Params': {'smoothing_level': 0.9999999850435392, 'smoothing_trend': 0.0, 'smoothing_seasonal': nan, 'damping_trend': nan, 'initial_level': -1.0783735441632214, 'initial_trend': 0.5293180071458381, 'initial_seasons': array([], dtype=float64), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели ExponentialSmoothing: {'Model': 'holt_winters', 'Params': {'smoothing_level': 1.4901161193847656e-08, 'smoothing_trend': 9.46705163371776e-11, 'smoothing_seasonal': 0.0, 'damping_trend': nan, 'initial_level': 0.44727529795662285, 'initial_trend': 0.4863021803382317, 'initial_seasons': array([-0.01886745,  2.50166087,  4.12851983,  4.29048977,  4.27994613,\n",
      "        1.38543857, -0.61040081, -2.94347873, -5.19962483, -4.8365329 ,\n",
      "       -4.50542346, -1.91459797]), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели Prophet: {'Model': 'prophet', 'Params': OrderedDict({'lp__': array([[316.325]]), 'k': array([[0.824076]]), 'm': array([[0.0210736]]), 'delta': array([[-2.78150e-09, -4.46361e-12,  4.50608e-10,  1.55135e-08,\n",
      "         8.78277e-09,  4.85360e-03,  5.89679e-03,  1.66776e-02,\n",
      "         2.79755e-02,  1.40440e-02,  4.00220e-05, -3.87814e-10,\n",
      "        -3.53351e-09,  3.59089e-09, -6.38809e-09,  1.55921e-09,\n",
      "        -2.12355e-07, -6.63889e-03, -1.20524e-02, -3.87302e-03,\n",
      "        -1.43610e-06, -6.53344e-09, -2.59482e-08,  1.84054e-09,\n",
      "         8.66133e-10]]), 'sigma_obs': array([[0.0254742]]), 'beta': array([[ 0.0843889 ,  0.0242499 , -0.0401913 , -0.222066  ,  0.0125492 ,\n",
      "        -0.0274832 ,  0.00207236,  0.0639601 ,  0.0772585 ,  0.0888946 ,\n",
      "        -0.110593  , -0.00897485,  0.0963918 , -0.0591778 ,  0.0195795 ,\n",
      "        -0.0696543 ,  0.0157192 ,  0.0105244 , -0.0801897 ,  0.203501  ]]), 'trend': array([[0.0210736, 0.0295523, 0.037484 , 0.0459627, 0.0541679, 0.0626466,\n",
      "        0.0708518, 0.0793305, 0.0878092, 0.0960144, 0.104493 , 0.112698 ,\n",
      "        0.121177 , 0.129656 , 0.137314 , 0.145793 , 0.153998 , 0.162477 ,\n",
      "        0.170682 , 0.179161 , 0.187689 , 0.195943 , 0.204471 , 0.212784 ,\n",
      "        0.221373 , 0.229962 , 0.237875 , 0.246636 , 0.255115 , 0.264163 ,\n",
      "        0.27292  , 0.281969 , 0.291018 , 0.299914 , 0.309108 , 0.318004 ,\n",
      "        0.327198 , 0.336392 , 0.344695 , 0.353889 , 0.362786 , 0.37198  ,\n",
      "        0.380877 , 0.390071 , 0.399264 , 0.408161 , 0.417355 , 0.426252 ,\n",
      "        0.435446 , 0.444639 , 0.45324  , 0.462434 , 0.471331 , 0.480524 ,\n",
      "        0.489421 , 0.498615 , 0.507809 , 0.516706 , 0.525831 , 0.534662 ,\n",
      "        0.543787 , 0.552789 , 0.560919 , 0.56992  , 0.578593 , 0.587554 ,\n",
      "        0.596227 , 0.605188 , 0.61415  , 0.622822 , 0.631783 , 0.640456 ,\n",
      "        0.649417 , 0.658379 , 0.666473 , 0.675435 , 0.684107 , 0.693068 ,\n",
      "        0.701741 , 0.710702 , 0.719664 , 0.728336 , 0.737298 , 0.74597  ,\n",
      "        0.754932 , 0.763893 , 0.771987 , 0.780949 , 0.789621 , 0.798583 ,\n",
      "        0.807255 , 0.816216 , 0.825178 , 0.83385  , 0.842812 , 0.851484 ,\n",
      "        0.860446 , 0.869407 , 0.877791 , 0.886752 ]])})}\n"
     ]
    }
   ],
   "source": [
    "sklearn_models = [elastic_net, huber, lasso, ransac, ridge, theil_sen, random_forest, catboost]\n",
    "statsmodels_models = [simpexpsmoth, holt, expsmoothing]\n",
    "statsmodels_models_fit = [model_fit_simpexpsmoth, model_fit_holt, model_fit_expsmoothing]\n",
    "prophet_models = [model_prophet]\n",
    "for model in sklearn_models:\n",
    "    hyperparams = dataloader.get_params(model)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")\n",
    "for model, model_fit in zip(statsmodels_models, statsmodels_models_fit):\n",
    "    hyperparams = dataloader.get_params(model, model_fit)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")\n",
    "for model in prophet_models:\n",
    "    hyperparams = dataloader.get_params(model)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c4fa8",
   "metadata": {},
   "source": [
    "Пример сохранения библиотечных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "540c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in sklearn_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")\n",
    "for model in statsmodels_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")\n",
    "for model in prophet_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
