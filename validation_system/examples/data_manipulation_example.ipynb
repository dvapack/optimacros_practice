{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c9cf3b",
   "metadata": {},
   "source": [
    "В данном ноутбуке находятся примеры работы с классом Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import logging\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, HuberRegressor, Lasso, \\\n",
    "                                RANSACRegressor, Ridge, TheilSenRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from statsmodels.tsa.api import Holt, SimpleExpSmoothing, ExponentialSmoothing, SARIMAX\n",
    "import statsmodels\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json\n",
    "\n",
    "from validation_system.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09033d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(x: pd.Series, weights_coeffs: list) -> pd.Series:\n",
    "    return (x * pd.Series(weights_coeffs, index=x.index)).sum() / len(x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2b1192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_coefficients(ts: pd.Series, timestamps: pd.Series, time_step: str, timestamps_res: pd.DatetimeIndex) -> tuple[dict, pd.Series]:\n",
    "    \"\"\"\n",
    "    Вычисление сезонных коэффициентов на основе ряда.\n",
    "    :param ts: Временной ряд;\n",
    "    :param timestamps: Метка времени;\n",
    "    :param time_step: Шаг времени;\n",
    "    :param timestamps_res: Временные метки, для которых нужно получить коэффициенты\n",
    "    :return: Словарь с сезонными коэффициентами, временные метки\n",
    "    \"\"\"\n",
    "    mean_sales = np.mean(ts.values)\n",
    "    marks_res = None\n",
    "    marks = None\n",
    "    match time_step:\n",
    "        case 'YS':\n",
    "            marks = timestamps.dt.year\n",
    "            marks_res = timestamps_res.year\n",
    "        case 'QS':\n",
    "            marks = timestamps.dt.quarter\n",
    "            marks_res = timestamps_res.quarter\n",
    "        case 'MS':\n",
    "            marks = timestamps.dt.month\n",
    "            marks_res = timestamps_res.month\n",
    "        case 'W' | 'W-MON':\n",
    "            marks = (timestamps.dt.day - 1 + (\n",
    "                    timestamps - pd.to_timedelta(timestamps.dt.day - 1, unit='d')).dt.dayofweek) // 7 + 1\n",
    "            marks_res = (timestamps_res.day - 1 + (\n",
    "                    timestamps_res - pd.to_timedelta(timestamps_res.day - 1, unit='d')).dayofweek) // 7 + 1\n",
    "        case 'D':\n",
    "            marks = timestamps.dt.dayofweek\n",
    "            marks_res = timestamps_res.dayofweek\n",
    "    dict_seasonality = {}\n",
    "    df = pd.DataFrame({'ds': marks, 'y': ts})\n",
    "    for timestamp in marks.unique():\n",
    "        values = df[df.ds == timestamp].y\n",
    "        dict_seasonality[timestamp] = np.mean(values / mean_sales)\n",
    "    for timestamp in set(marks_res.unique()) - set(marks.unique()):\n",
    "        dict_seasonality[timestamp] = dict_seasonality.get(timestamp, 1)\n",
    "    return dict_seasonality, marks_res\n",
    "\n",
    "def calculate_weights_coeffs(n: int, weights_type: str, weights_coeffs: list) -> list:\n",
    "    \"\"\"\n",
    "    Вычисление коэффициента весов на основе заданного типа весов и количества элементов\n",
    "    :param n: Количество эламентов;\n",
    "    :param weights_type: Тип весов;\n",
    "    :param weights_coeffs: Изначальные коэффициенты весов;\n",
    "    :return: Коэффициенты весов\n",
    "    \"\"\"\n",
    "    if weights_type == 'custom':\n",
    "        return weights_coeffs\n",
    "    elif weights_type == 'new':\n",
    "        reverse = False\n",
    "    elif weights_type == 'old':\n",
    "        reverse = True\n",
    "    else:\n",
    "        logging.exception(f'Передан несуществующий режим \"{weights_type}\". '\n",
    "                          f'Необходимо выбирать режимы: \"new\", \"old\", \"custom\". '\n",
    "                          f'Для данного пересечения будет по умолчанию будет выбран метод \"new\".')\n",
    "        reverse = False\n",
    "    a1 = 0.001\n",
    "    d = (2 - 2 * a1 * n) / (n * (n - 1))\n",
    "    res = [a1 + d * i for i in range(0, n)]\n",
    "    res.sort(reverse=reverse)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b7163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def const(ts: pd.Series, n_predict: int, type: str) -> tuple[pd.Series, float]:\n",
    "    \"\"\"\n",
    "    Прогноз - константа\n",
    "    :param ts: Временной ряд;\n",
    "    :param n_predict: Количество предсказаний;\n",
    "    :param type: Тип константы;\n",
    "    :return: Фрейм с предсказанием\n",
    "    \"\"\"\n",
    "    n = len(ts.index)\n",
    "    value = None\n",
    "    match (type):\n",
    "        case 'Moda':\n",
    "            value = ts.mode()[0]\n",
    "        case 'Mean':\n",
    "            value = ts.mean()\n",
    "        case 'Min':\n",
    "            value = ts.min()\n",
    "        case 'Max':\n",
    "            value = ts.max()\n",
    "        case 'Median':\n",
    "            value = ts.median()\n",
    "\n",
    "    ts_res = pd.Series(value, index=range(n + n_predict), dtype='float64')\n",
    "    return ts_res, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4395e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rol_mean_fit(timestamps: pd.Series, time_step: str, ts: pd.Series, n_predict: int, window_size: int,\n",
    "                 weights_coeffs: list, weights_type: str, sample: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Создает скользящее среднее, формирует список компонентов\n",
    "\n",
    "    :param ts: Временной ряд\n",
    "    :param n_predict: Количество периодов для прогнозирования\n",
    "    :param window_size: Размер окна\n",
    "    :param weights_coeffs: Весовые коэффциенты\n",
    "    :param weights_type: Тип весов\n",
    "    :param sample: Датафрейм с признаками (не используется);\n",
    "    :return: Прогноз\n",
    "    \"\"\"\n",
    "    weights_coeffs = calculate_weights_coeffs(window_size, weights_type, weights_coeffs)\n",
    "    ts_res = ts.copy()\n",
    "    ts_base = None\n",
    "    for i in range(n_predict):\n",
    "        ts_res[len(ts_res.index)] = np.nan\n",
    "        rol = ts_res.fillna(0).rolling(window_size)\n",
    "        if i == 0:\n",
    "            ts_base = rol.apply(lambda x: weighted_mean(x, weights_coeffs)).shift(1)[:-1]\n",
    "            ts_base[:window_size] = ts[:window_size].values\n",
    "        ts_res = ts_res.where(pd.notna, other=rol.apply(lambda x: weighted_mean(x, weights_coeffs)).shift(1))\n",
    "    ts_res.loc[ts_base.index] = ts_base.values\n",
    "    return ts_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac9819c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def croston_tsb_fit(timestamps: pd.Series, ts: pd.Series, alpha: float, beta: float, n_predict: int,\n",
    "                    time_step: str, sample: pd.DataFrame) -> tuple[pd.Series, dict]:\n",
    "    \"\"\"\n",
    "    Прогноз - метод Кростона.\n",
    "    :param timestamps: Временные метки;\n",
    "    :param ts: Временной ряд;\n",
    "    :param alpha: Параметр сглаживания для уровня;\n",
    "    :param beta: Параметр сглаживания для вероятности;\n",
    "    :param n_predict: Количество предсказаний;\n",
    "    :param time_step: Шаг прогноза;\n",
    "    :param sample: Датафрейм с признаками (не используется);\n",
    "    :return: Фрейм с предсказанием\n",
    "    \"\"\"\n",
    "    d = np.array(ts)\n",
    "    cols = len(d)\n",
    "    d = np.append(d, [np.nan] * n_predict)\n",
    "\n",
    "    # Уровень(a), Вероятность(p), Прогноз(f)\n",
    "    a, p, f = np.full((3, cols + n_predict + 1), np.nan)\n",
    "\n",
    "    # Инициализация\n",
    "    first_occurrence = np.argmax(d[:cols] > 0)\n",
    "    a[0] = d[first_occurrence]\n",
    "    p[0] = 1 / (1 + first_occurrence)\n",
    "    f[0] = p[0] * a[0]\n",
    "\n",
    "    # Заполнение матриц уровня и вероятности, прогноз\n",
    "    for t in range(cols):\n",
    "        if d[t] > 0:\n",
    "            a[t + 1] = alpha * d[t] + (1 - alpha) * a[t]\n",
    "            p[t + 1] = beta * 1 + (1 - beta) * p[t]\n",
    "        else:\n",
    "            a[t + 1] = a[t]\n",
    "            p[t + 1] = (1 - beta) * p[t]\n",
    "        f[t + 1] = p[t + 1] * a[t + 1]\n",
    "    a[cols + 1:cols + n_predict + 1] = a[cols]\n",
    "    p[cols + 1:cols + n_predict + 1] = p[cols]\n",
    "    f[cols + 1:cols + n_predict + 1] = f[cols]\n",
    "\n",
    "    ts_res = pd.Series(index=range(cols + n_predict), dtype='float64')\n",
    "    ts_res.loc[ts_res.index] = f[1:]\n",
    "    timestamps_res = pd.date_range(start=timestamps.iloc[0], freq=time_step, periods=len(ts_res))\n",
    "    dict_seasonality, marks_res = seasonal_coefficients(ts, timestamps, time_step, timestamps_res)\n",
    "    df = pd.DataFrame({'y_pred': ts_res, 'indexes': marks_res})\n",
    "    df.loc[cols + 1:cols + n_predict + 1, 'y_pred'] = df.iloc[cols + 1:cols + n_predict + 1].apply(\n",
    "        lambda x: x.y_pred * dict_seasonality[x.indexes], axis=1)\n",
    "    return df.y_pred.reset_index(drop=True)  # , {'alpha': alpha, 'beta': beta}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51cf278",
   "metadata": {},
   "source": [
    "Пример загрузки данных от optimacros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46064614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['croston_tsb', 'elastic_net', 'exp_smoothing', 'holt', 'holt_winters', 'huber', 'lasso', 'polynomial', 'ransac', 'ridge', 'rol_mean', 'theil_sen', 'const', 'catboost', 'sarima', 'prophet', 'random_forest', 'symfit_fourier_fft']\n",
      "Hyperparams: [{'croston_tsb_min_alpha': 0, 'croston_tsb_max_alpha': 1, 'croston_tsb_min_beta': 0, 'croston_tsb_max_beta': 1, 'croston_tsb_step': 0.1}, {'elastic_net_min_alpha': 0, 'elastic_net_max_alpha': 1, 'elastic_net_max_l1': 1, 'elastic_net_min_l1': 0, 'elastic_net_step': 0.05}, {'exp_smoothing_min_alpha': 0, 'exp_smoothing_max_alpha': 1, 'exp_smoothing_step': 0.1}, {'holt_min_alpha': 0, 'holt_max_alpha': 1, 'holt_min_beta': 0, 'holt_max_beta': 1, 'holt_step': 0.1}, {'holt_winters_min_seasonality': 2, 'holt_winters_max_seasonality': 7, 'holt_winters_trend_types': ['add', 'mul', None], 'holt_winters_seasonal_types': ['add', 'mul', None]}, {'huber_min_degrees': 1, 'huber_max_degrees': 5}, {'lasso_min_alpha': 0, 'lasso_max_alpha': 1, 'lasso_step': 0.05}, {'polynomial_min_degrees': 2, 'polynomial_max_degrees': 5}, {'ransac_min_degrees': 1, 'ransac_max_degrees': 5}, {'ridge_min_alpha': 0, 'ridge_max_alpha': 1, 'ridge_step': 0.05}, {'rol_mean_min_window_size': 2, 'rol_mean_max_window_size': 10, 'rol_mean_weights_type': 'new', 'rol_mean_weights_coeffs': 2}, {'theil_sen_min_degrees': 1, 'theil_sen_max_degrees': 5}, {'type': 'Median'}, {'learning_rate': [0.075, 0.1, 0.3, 0.5], 'n_estimators': [1, 5, 10, 15, 20, 25, 30], 'depth': [1, 2, 4, 8, 10]}, {'min_p': 0, 'max_p': 1, 'min_d': 0, 'max_d': 1, 'min_q': 0, 'max_q': 1, 'min_P': 0, 'max_P': 1, 'min_D': 0, 'max_D': 1, 'min_Q': 0, 'max_Q': 1}, {'seasonality_mode': ['additive', 'multiplicative'], 'changepoint_prior_scale': [0.001, 0.5], 'seasonality_prior_scale': [0.1, 10.0]}, {'n_estimators': [1, 5, 10, 15, 20, 25, 30], 'max_features': [1.0, 'log2', 'sqrt'], 'max_depth': [1, 2, 4, 8, 10], 'min_samples_split': [2, 10, 20, 30], 'min_samples_leaf': [2, 10, 20, 30]}, {'min_components': 1, 'max_components': 9}]\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\"om_correct.csv\")\n",
    "models, hyperparams = dataloader.load_hyperparams_from_optimacros()\n",
    "print(f\"Models: {models}\")\n",
    "print(f\"Hyperparams: {hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3080cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebb6fe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции генерации данных определены.\n",
      "Сгенерированы данные для регрессии: X_reg.shape=(100, 5), y_reg.shape=(100,)\n",
      "Сгенерированы данные для временных рядов: df_ts.shape=(100, 2)\n"
     ]
    }
   ],
   "source": [
    "def generate_regression_data(n_samples=100, n_features=5):\n",
    "    \"\"\"Генерирует фейковые данные для задач регрессии.\"\"\"\n",
    "    X = np.random.rand(n_samples, n_features) * 10\n",
    "    # Простое линейное отношение с шумом\n",
    "    true_coef = np.array([1.5, -0.8, 0.5, 2.1, -1.2][:n_features])\n",
    "    y = X @ true_coef + np.random.normal(0, 2, n_samples)\n",
    "    return pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(n_features)]), pd.Series(y, name='target')\n",
    "\n",
    "def generate_time_series_data(n_points=100, trend_strength=0.5, seasonality_period=12, seasonality_strength=5):\n",
    "    \"\"\"Генерирует фейковые данные временного ряда с трендом и сезонностью.\"\"\"\n",
    "    dates = pd.date_range(start='2020-01-01', periods=n_points, freq='MS')\n",
    "    time_index = np.arange(n_points)\n",
    "\n",
    "    # ТРЕНД\n",
    "    trend = trend_strength * time_index\n",
    "\n",
    "    # СЕЗОННОСТЬ\n",
    "    seasonality = seasonality_strength * np.sin(2 * np.pi * time_index / seasonality_period)\n",
    "\n",
    "    # ШУМ\n",
    "    noise = np.random.normal(0, 1.5, n_points)\n",
    "\n",
    "    # ОБЩИЙ РЯД\n",
    "    y = trend + seasonality + noise\n",
    "\n",
    "    df = pd.DataFrame({'ds': dates, 'y': y}) # 'ds' и 'y' - обязательные названия для Prophet\n",
    "    return df\n",
    "\n",
    "print(\"Функции генерации данных определены.\")\n",
    "\n",
    "# Генерируем данные для регрессии\n",
    "X_reg, y_reg = generate_regression_data()\n",
    "print(f\"Сгенерированы данные для регрессии: X_reg.shape={X_reg.shape}, y_reg.shape={y_reg.shape}\")\n",
    "\n",
    "# Генерируем данные для временных рядов\n",
    "df_ts = generate_time_series_data()\n",
    "print(f\"Сгенерированы данные для временных рядов: df_ts.shape={df_ts.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75501a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ElasticNet успешно обучена.\n",
      "  HuberRegressor успешно обучена.\n",
      "  Lasso успешно обучена.\n",
      "  RANSACRegressor успешно обучена.\n",
      "  Ridge успешно обучена.\n",
      "  TheilSenRegressor успешно обучена.\n",
      "  RandomForestRegressor успешно обучена.\n",
      "  CatBoostRegressor успешно обучена.\n",
      "  SimpleExpSmoothing успешно обучена.\n",
      "  Holt успешно обучена.\n",
      "  ExponentialSmoothing успешно обучена.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/home/flowers/anaconda3/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "15:31:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:31:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SARIMAX успешно обучена.\n",
      "  Prophet успешно обучена.\n"
     ]
    }
   ],
   "source": [
    "elastic_net = ElasticNet(random_state=42)\n",
    "try:\n",
    "    elastic_net.fit(X_reg, y_reg)\n",
    "    y_pred_en = elastic_net.predict(X_reg.head(5))\n",
    "    print(\"  ElasticNet успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении ElasticNet: {e}\")\n",
    "\n",
    "huber = HuberRegressor()\n",
    "try:\n",
    "    huber.fit(X_reg, y_reg)\n",
    "    y_pred_huber = huber.predict(X_reg.head(5))\n",
    "    print(\"  HuberRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении HuberRegressor: {e}\")\n",
    "\n",
    "lasso = Lasso(random_state=42)\n",
    "try:\n",
    "    lasso.fit(X_reg, y_reg)\n",
    "    y_pred_lasso = lasso.predict(X_reg.head(5))\n",
    "    print(\"  Lasso успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Lasso: {e}\")\n",
    "\n",
    "ransac = RANSACRegressor(random_state=42)\n",
    "try:\n",
    "    ransac.fit(X_reg, y_reg)\n",
    "    y_pred_ransac = ransac.predict(X_reg.head(5))\n",
    "    print(\"  RANSACRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении RANSACRegressor: {e}\")\n",
    "\n",
    "ridge = Ridge(random_state=42)\n",
    "try:\n",
    "    ridge.fit(X_reg, y_reg)\n",
    "    y_pred_ridge = ridge.predict(X_reg.head(5))\n",
    "    print(\"  Ridge успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Ridge: {e}\")\n",
    "\n",
    "theil_sen = TheilSenRegressor(random_state=42)\n",
    "try:\n",
    "    theil_sen.fit(X_reg, y_reg)\n",
    "    y_pred_theil_sen = theil_sen.predict(X_reg.head(5))\n",
    "    print(\"  TheilSenRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении TheilSenRegressor: {e}\")\n",
    "\n",
    "random_forest = RandomForestRegressor(random_state=42, n_estimators=50)\n",
    "try:\n",
    "    random_forest.fit(X_reg, y_reg)\n",
    "    y_pred_rf = random_forest.predict(X_reg.head(5))\n",
    "    print(\"  RandomForestRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении RandomForestRegressor: {e}\")\n",
    "\n",
    "catboost = CatBoostRegressor(random_state=42, verbose=0, iterations=50)\n",
    "try:\n",
    "    catboost.fit(X_reg, y_reg)\n",
    "    y_pred_cat = catboost.predict(X_reg.head(5))\n",
    "    print(\"  CatBoostRegressor успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении CatBoostRegressor: {e}\")\n",
    "\n",
    "y_ts = df_ts.set_index('ds')['y']\n",
    "\n",
    "models_ts_statsmodels = {\n",
    "    \"SimpleExpSmoothing\": SimpleExpSmoothing(y_ts, initialization_method=\"estimated\"),\n",
    "    \"Holt\": Holt(y_ts, initialization_method=\"estimated\"),\n",
    "    \"ExponentialSmoothing\": ExponentialSmoothing(y_ts, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\")\n",
    "}\n",
    "\n",
    "simpexpsmoth = SimpleExpSmoothing(y_ts, initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_simpexpsmoth = simpexpsmoth.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_simpexpsmoth = model_fit_simpexpsmoth.forecast(forecast_steps)\n",
    "    print(\"  SimpleExpSmoothing успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении SimpleExpSmoothing: {e}\")\n",
    "\n",
    "holt = Holt(y_ts, initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_holt = holt.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_holt = model_fit_holt.forecast(forecast_steps)\n",
    "    print(\"  Holt успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Holt: {e}\")\n",
    "\n",
    "expsmoothing = ExponentialSmoothing(y_ts, seasonal_periods=12, trend='add', seasonal='add', initialization_method=\"estimated\")\n",
    "try:\n",
    "    model_fit_expsmoothing = expsmoothing.fit()\n",
    "    forecast_steps = 5\n",
    "    forecast_expsmoothing = model_fit_expsmoothing.forecast(forecast_steps)\n",
    "    print(\"  ExponentialSmoothing успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении ExponentialSmoothing: {e}\")\n",
    "\n",
    "sarimax = SARIMAX(y_ts, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12), enforce_stationarity=False, enforce_invertibility=False)\n",
    "try:\n",
    "    model_fit_sarimax = sarimax.fit(disp=False)\n",
    "    forecast_steps = 5\n",
    "    forecast_sarimax = model_fit_sarimax.forecast(forecast_steps)\n",
    "    print(\"  SARIMAX успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении SARIMAX: {e}\")\n",
    "\n",
    "model_prophet = Prophet()\n",
    "try:\n",
    "    model_prophet.fit(df_ts)\n",
    "    future = model_prophet.make_future_dataframe(periods=5, freq='MS')\n",
    "    forecast_prophet = model_prophet.predict(future)\n",
    "    print(\"  Prophet успешно обучена.\")\n",
    "except Exception as e:\n",
    "    print(f\"  Ошибка при обучении Prophet: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ee024",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc898f59",
   "metadata": {},
   "source": [
    "Пример получения гиперпараметров моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a563237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперпараметры модели ElasticNet: {'Model': 'ElasticNet', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}}\n",
      "Гиперпараметры модели HuberRegressor: {'Model': 'HuberRegressor', 'Params': {'alpha': 0.0001, 'epsilon': 1.35, 'fit_intercept': True, 'max_iter': 100, 'tol': 1e-05, 'warm_start': False}}\n",
      "Гиперпараметры модели Lasso: {'Model': 'ElasticNet', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': 42, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}}\n",
      "Гиперпараметры модели RANSACRegressor: {'Model': 'RANSACRegressor', 'Params': {'estimator': None, 'is_data_valid': None, 'is_model_valid': None, 'loss': 'absolute_error', 'max_skips': inf, 'max_trials': 100, 'min_samples': None, 'random_state': 42, 'residual_threshold': None, 'stop_n_inliers': inf, 'stop_probability': 0.99, 'stop_score': inf}}\n",
      "Гиперпараметры модели Ridge: {'Model': 'Ridge', 'Params': {'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 42, 'solver': 'auto', 'tol': 0.0001}}\n",
      "Гиперпараметры модели TheilSenRegressor: {'Model': 'TheilSenRegressor', 'Params': {'copy_X': True, 'fit_intercept': True, 'max_iter': 300, 'max_subpopulation': 10000.0, 'n_jobs': None, 'n_subsamples': None, 'random_state': 42, 'tol': 0.001, 'verbose': False}}\n",
      "Гиперпараметры модели RandomForestRegressor: {'Model': 'RandomForestRegressor', 'Params': {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}}\n",
      "Гиперпараметры модели CatBoostRegressor: {'Model': 'CatBoostRegressor', 'Params': {'iterations': 50, 'loss_function': 'RMSE', 'verbose': 0, 'random_state': 42}}\n",
      "Гиперпараметры модели SimpleExpSmoothing: {'Model': 'ExpSmoothing', 'Params': {'smoothing_level': 0.9999999843600919, 'smoothing_trend': nan, 'smoothing_seasonal': nan, 'damping_trend': nan, 'initial_level': -0.27629577401300076, 'initial_trend': nan, 'initial_seasons': array([], dtype=float64), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели Holt: {'Model': 'Holt', 'Params': {'smoothing_level': 0.9999999850988388, 'smoothing_trend': 0.0, 'smoothing_seasonal': nan, 'damping_trend': nan, 'initial_level': -0.8438830224356809, 'initial_trend': 0.5677085655921876, 'initial_seasons': array([], dtype=float64), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели ExponentialSmoothing: {'Model': 'HoltWinters', 'Params': {'smoothing_level': 1.4972121202943614e-08, 'smoothing_trend': 1.799427079758965e-10, 'smoothing_seasonal': 7.079476094060582e-11, 'damping_trend': nan, 'initial_level': -0.0989561785785633, 'initial_trend': 0.49834917707738274, 'initial_seasons': array([-0.51446807,  1.3496237 ,  4.18954795,  4.58878679,  4.120447  ,\n",
      "        2.79099945, -0.16207946, -2.03901016, -4.33645862, -5.35177433,\n",
      "       -4.76896814, -3.17052351]), 'use_boxcox': False, 'lamda': None, 'remove_bias': False}}\n",
      "Гиперпараметры модели Prophet: {'Model': 'Prophet', 'Params': OrderedDict({'lp__': array([[329.599]]), 'k': array([[0.863772]]), 'm': array([[0.00935853]]), 'delta': array([[-1.00627e-09, -1.59715e-09,  2.35374e-08, -5.45114e-09,\n",
      "         1.71688e-09,  2.70311e-06,  4.51074e-03,  5.81019e-04,\n",
      "         2.37736e-04,  1.88964e-03,  3.68986e-03,  1.19085e-02,\n",
      "         1.84692e-03,  4.55838e-04,  1.34985e-05, -8.07460e-09,\n",
      "        -1.28095e-08,  1.33093e-08, -3.68889e-10, -3.60449e-09,\n",
      "        -2.09804e-09,  3.97994e-09, -5.11059e-09, -4.38139e-09,\n",
      "         2.70381e-09]]), 'sigma_obs': array([[0.0228057]]), 'beta': array([[ 0.0983843 ,  0.00506957, -0.00520616,  0.00917795, -0.0156005 ,\n",
      "         0.00074893, -0.0665778 ,  0.110536  ,  0.05128   , -0.00435881,\n",
      "         0.0785606 ,  0.00345782,  0.0532075 ,  0.0194775 , -0.0425751 ,\n",
      "        -0.128797  , -0.0220804 , -0.0128989 , -0.0160416 , -0.0101116 ]]), 'trend': array([[0.00935853, 0.0182457 , 0.0265594 , 0.0354466 , 0.044047  ,\n",
      "        0.0529341 , 0.0615346 , 0.0704217 , 0.0793088 , 0.0879093 ,\n",
      "        0.0967964 , 0.105397  , 0.114284  , 0.123171  , 0.131198  ,\n",
      "        0.140085  , 0.148686  , 0.157573  , 0.166173  , 0.17506   ,\n",
      "        0.183948  , 0.192548  , 0.201435  , 0.210081  , 0.219014  ,\n",
      "        0.227948  , 0.236022  , 0.244962  , 0.253613  , 0.262555  ,\n",
      "        0.271208  , 0.28015   , 0.289092  , 0.297765  , 0.306726  ,\n",
      "        0.315399  , 0.324398  , 0.333397  , 0.341526  , 0.350648  ,\n",
      "        0.359475  , 0.368597  , 0.377443  , 0.386584  , 0.395725  ,\n",
      "        0.404576  , 0.413722  , 0.422572  , 0.431718  , 0.440864  ,\n",
      "        0.449419  , 0.458565  , 0.467416  , 0.476562  , 0.485412  ,\n",
      "        0.494558  , 0.503704  , 0.512555  , 0.5217    , 0.530551  ,\n",
      "        0.539697  , 0.548842  , 0.557103  , 0.566249  , 0.5751    ,\n",
      "        0.584245  , 0.593096  , 0.602242  , 0.611388  , 0.620238  ,\n",
      "        0.629384  , 0.638235  , 0.647381  , 0.656526  , 0.664787  ,\n",
      "        0.673933  , 0.682784  , 0.691929  , 0.70078   , 0.709926  ,\n",
      "        0.719071  , 0.727922  , 0.737068  , 0.745919  , 0.755064  ,\n",
      "        0.76421   , 0.772471  , 0.781617  , 0.790467  , 0.799613  ,\n",
      "        0.808464  , 0.81761   , 0.826755  , 0.835606  , 0.844752  ,\n",
      "        0.853603  , 0.862748  , 0.871894  , 0.88045   , 0.889596  ]])})}\n"
     ]
    }
   ],
   "source": [
    "sklearn_models = [elastic_net, huber, lasso, ransac, ridge, theil_sen, random_forest, catboost]\n",
    "statsmodels_models = [simpexpsmoth, holt, expsmoothing]\n",
    "statsmodels_models_fit = [model_fit_simpexpsmoth, model_fit_holt, model_fit_expsmoothing]\n",
    "prophet_models = [model_prophet]\n",
    "for model in sklearn_models:\n",
    "    hyperparams = dataloader.get_params(model)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")\n",
    "for model, model_fit in zip(statsmodels_models, statsmodels_models_fit):\n",
    "    hyperparams = dataloader.get_params(model, model_fit)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")\n",
    "for model in prophet_models:\n",
    "    hyperparams = dataloader.get_params(model)\n",
    "    print(f\"Гиперпараметры модели {model.__class__.__name__}: {hyperparams}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c4fa8",
   "metadata": {},
   "source": [
    "Пример сохранения библиотечных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "540c7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in sklearn_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")\n",
    "for model in statsmodels_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")\n",
    "for model in prophet_models:\n",
    "    dataloader.save_trained_model(model, f\"saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
