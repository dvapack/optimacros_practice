{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da80ee68",
   "metadata": {},
   "source": [
    "В данном ноутбуке представлены примеры использования класса Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3df2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, HuberRegressor, Lasso, \\\n",
    "                                RANSACRegressor, Ridge, TheilSenRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from statsmodels.tsa.api import Holt, SimpleExpSmoothing, ExponentialSmoothing, SARIMAX\n",
    "from prophet import Prophet\n",
    "from prophet.serialize import model_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b834aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation():\n",
    "    \"\"\"\n",
    "    Класс для валидации гиперпараметров\n",
    "    \"\"\"\n",
    "    def __init__(self, models: list, hyperparams: list):\n",
    "        \"\"\"\n",
    "        :param models: Список моделей для валидации;\n",
    "        :param hyperparams: Список соответствующих гиперпараметров для валидации\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.hyperparams = hyperparams\n",
    "\n",
    "    def __to_list(self, value) -> list:\n",
    "        \"\"\"\n",
    "        Метод для преобразования итерируемого объекта или числа к списку.\n",
    "\n",
    "        :param value: Число или итерируемый объект.\n",
    "        :return: Список.\n",
    "        \"\"\"\n",
    "        if isinstance(value, list):\n",
    "            return value\n",
    "        elif isinstance(value, (int, float, str)):\n",
    "            return [value]\n",
    "        elif isinstance(value, (tuple, set)):\n",
    "            return list(value)\n",
    "        else:\n",
    "            raise TypeError(\"Неподдерживаемый тип данных для преобразования в список\")\n",
    "\n",
    "    def __check_lists_equal(self, list_a: list, list_b: list):\n",
    "        \"\"\"\n",
    "        Метод для проверки эквивалентности двух списков (порядок не важен)\n",
    "\n",
    "        :param list_a: Первый список для сравнения;\n",
    "        :param list_b: Второй список для сравнения.\n",
    "        \"\"\"\n",
    "        if set(list_a) != set(list_b):\n",
    "            raise ValueError(\"Элементы в списках не совпадают\")\n",
    "    \n",
    "    def __check_list_is_subset(self, list_a: list, list_b: list):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что один список является подмножеством другого списка\n",
    "\n",
    "        :param list_a: Исходный список;\n",
    "        :param list_b: Список для проверки, является ли он подмножеством.\n",
    "        \"\"\"\n",
    "        if not set(list_b).issubset(list_a):\n",
    "            raise ValueError(\"В списке находятся недопустимые значения\")\n",
    "        \n",
    "    def __strong_check_value(self, number, left_border, right_border):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что число строго находится в допустимом диапазоне, т.е > или <\n",
    "\n",
    "        :param number: Число для проверки;\n",
    "        :param left_boarder: Левая граница проверки;\n",
    "        :param right_border: Правая граница проверки;\n",
    "        \"\"\"\n",
    "        if not (number > left_border and number < right_border):\n",
    "            raise ValueError(\"Число находятся вне разрешенного диапазона\")\n",
    "        \n",
    "    def __check_value(self, number, left_border, right_border):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что число находится в допустимом диапазоне, т.е >= или <=.\n",
    "\n",
    "        :param number: Число для проверки;\n",
    "        :param left_boarder: Левая граница проверки;\n",
    "        :param right_border: Правая граница проверки;\n",
    "        \"\"\"\n",
    "        if not (number >= left_border and number <= right_border):\n",
    "            raise ValueError(\"Число находятся вне разрешенного диапазона\")\n",
    "    \n",
    "    def __strong_check_values(self, list: list, left_border, right_border, default_value, param: str):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что числа в списке строго находятся в допустимом диапазоне (> и <). Если это не так,\n",
    "        число заменяется на стандартное значение\n",
    "\n",
    "        :param list: Список чисел для проверки;\n",
    "        :param left_boarder: Левая граница проверки;\n",
    "        :param right_border: Правая граница проверки;\n",
    "        :param default_value: Стандартное значение для замены некорректных данных;\n",
    "        :param param: Название параметра для вывода в случае ошибки.\n",
    "        \"\"\"\n",
    "        for number in list:\n",
    "            try:\n",
    "                number = self.__strong_check_value(number, left_border, right_border)\n",
    "            except ValueError:\n",
    "                print(f\"{param} - некорректное значение {number}, заменено на {default_value}\")\n",
    "                number = default_value\n",
    "    \n",
    "    def __check_values(self, list: list, left_border, right_border, default_value, param: str):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что числа в списке находятся в допустимом диапазоне (>= и <=). Если это не так,\n",
    "        число заменяется на стандартное значение\n",
    "\n",
    "        :param list: Список чисел для проверки;\n",
    "        :param left_boarder: Левая граница проверки;\n",
    "        :param right_border: Правая граница проверки;\n",
    "        :param default_value: Стандартное значение для замены некорректных данных;\n",
    "        :param param: Название параметра для вывода в случае ошибки.\n",
    "        \"\"\"\n",
    "        for number in list:\n",
    "            try:\n",
    "                number = self.__check_value(number, left_border, right_border)\n",
    "            except ValueError:\n",
    "                print(f\"{param} - некорректное значение {number}, заменено на {default_value}\")\n",
    "                number = default_value\n",
    "\n",
    "    def __croston_tsb(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Croston TSB\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"croston_tsb_min_alpha\", \"croston_tsb_max_alpha\", \n",
    "                            \"croston_tsb_min_beta\", \"croston_tsb_max_beta\",\n",
    "                            \"croston_tsb_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"croston_tsb - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_min_beta = 0\n",
    "        default_max_beta = 1\n",
    "        default_step = 0.1\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 1\n",
    "        provided_min_alpha = self.__to_list(data.get(\"croston_tsb_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"croston_tsb_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"croston_tsb_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"croston_tsb_max_alpha\")\n",
    "        # проверка beta\n",
    "        min_beta = 0\n",
    "        max_beta = 1\n",
    "        provided_min_beta = self.__to_list(data.get(\"croston_tsb_min_beta\"))\n",
    "        self.__check_values(provided_min_beta, min_beta, max_beta, default_min_beta, \"croston_tsb_min_beta\")\n",
    "        provided_max_beta = self.__to_list(data.get(\"croston_tsb_max_beta\"))\n",
    "        # проверка, чтобы max_beta был > min_beta\n",
    "        self.__check_values(provided_max_beta, provided_min_beta[0], max_beta, default_max_beta, \"croston_tsb_max_beta\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"croston_tsb_step\"))\n",
    "        self.__strong_check_values(provided_step, min_step, max_step, default_step, \"croston_tsb_step\")     \n",
    "    \n",
    "    def __elastic_net(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Elastic Net\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"elastic_net_min_alpha\", \"elastic_net_max_alpha\", \n",
    "                            \"elastic_net_min_l1\", \"elastic_net_max_l1\",\n",
    "                            \"elastic_net_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"elastic_net - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_min_l1 = 0\n",
    "        default_max_l1 = 1\n",
    "        default_step = 0.05\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 5 # в документации sklearn до бесконечности\n",
    "        provided_min_alpha = self.__to_list(data.get(\"elastic_net_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"elastic_net_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"elastic_net_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"elastic_net_max_alpha\")\n",
    "        # проверка l1\n",
    "        min_l1 = 0\n",
    "        max_l1 = 1\n",
    "        provided_min_l1 = self.__to_list(data.get(\"elastic_net_min_l1\"))\n",
    "        self.__check_values(provided_min_l1, min_l1, max_l1, default_min_l1, \"elastic_net_min_l1\")\n",
    "        provided_max_l1 = self.__to_list(data.get(\"elastic_net_max_l1\"))\n",
    "        # проверка, чтобы max_l1 был > min_l1\n",
    "        self.__check_values(provided_max_l1, provided_min_l1[0], max_l1, default_max_l1, \"elastic_net_max_l1\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"elastic_net_step\"))\n",
    "        self.__check_values(provided_step, min_step, max_step, default_step, \"elastic_net_step\")     \n",
    "\n",
    "    def __exp_smoothing(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Expontetial Smoothing\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"exp_smoothing_min_alpha\", \"exp_smoothing_max_alpha\", \n",
    "                            \"exp_smoothing_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"exp_smoothing {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_step = 0.1\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 1\n",
    "        provided_min_alpha = self.__to_list(data.get(\"exp_smoothing_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"exp_smoothing_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"exp_smoothing_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"exp_smoothing_max_alpha\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"exp_smoothing_step\"))\n",
    "        self.__check_values(provided_step, min_step, max_step, default_step, \"exp_smoothing_step\")\n",
    "\n",
    "    def __holt(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Holt\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"holt_min_alpha\", \"holt_max_alpha\",\n",
    "                            \"holt_min_beta\", \"holt_max_beta\",\n",
    "                            \"holt_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"holt - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_min_beta = 0\n",
    "        default_max_beta = 1\n",
    "        default_step = 0.1\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 1\n",
    "        provided_min_alpha = self.__to_list(data.get(\"holt_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"holt_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"holt_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"holt_max_alpha\")\n",
    "        # проверка beta\n",
    "        min_beta = 0\n",
    "        max_beta = 1\n",
    "        provided_min_beta = self.__to_list(data.get(\"holt_min_beta\"))\n",
    "        self.__check_values(provided_min_beta, min_beta, max_beta, default_min_beta, \"holt_min_beta\")\n",
    "        provided_max_beta = self.__to_list(data.get(\"holt_max_beta\"))\n",
    "        # проверка, чтобы max_beta был > min_beta\n",
    "        self.__check_values(provided_max_beta, provided_min_beta[0], max_beta, default_max_beta, \"holt_max_beta\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"holt_step\"))\n",
    "        self.__check_values(provided_step, min_step, max_step, default_step, \"holt_step\")\n",
    "\n",
    "#### переделать метод для holt_winters\n",
    "    def __holt_winters(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Holt Winters\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        default_params = [\"holt_winters_min_seasonality\", \"holt_winters_max_seasonality\",\n",
    "                          \"holt_winters_trend_types\", \"holt_winters_seasonal_types\"]\n",
    "        provided_params = list(data.keys())\n",
    "        self.__check_lists_equal(default_params, provided_params)\n",
    "        # задаём стандартные значения\n",
    "        default_trend_types = [\"add\", \"mul\", None]\n",
    "        default_seasonal_types = [\"add\", \"mul\", None]\n",
    "        default_sesonalities = {\n",
    "            \"Year\": [4, 6, 12, 52, 365],\n",
    "            \"Week\": [7, 14],\n",
    "            \"Daily\": [24, 48]\n",
    "        }\n",
    "\n",
    "    def __huber(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Huber\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"huber_min_degrees\", \"huber_max_degrees\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"huber - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_degrees = 1\n",
    "        default_max_degrees = 1.35 # в доке sklearn это стандартное значение\n",
    "        # проверка alpha\n",
    "        min_degrees = 1\n",
    "        max_degrees = 100\n",
    "        provided_min_degrees = self.__to_list(data.get(\"huber_min_degrees\"))\n",
    "        self.__check_values(provided_min_degrees, min_degrees, max_degrees, default_min_degrees, \"huber_min_degrees\")\n",
    "        provided_max_degrees = self.__to_list(data.get(\"huber_max_degrees\"))\n",
    "        # проверка, чтобы max_degrees был > min_degrees\n",
    "        self.__check_values(provided_max_degrees, provided_min_degrees[0], max_degrees, default_max_degrees, \"huber_max_degrees\")\n",
    "\n",
    "    def __lasso(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Lasso\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"lasso_min_alpha\", \"lasso_max_alpha\", \n",
    "                            \"lasso_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"lasso - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_step = 0.05\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 5 # в документации sklearn до бесконечности \n",
    "        provided_min_alpha = self.__to_list(data.get(\"lasso_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"lasso_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"lasso_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"lasso_max_alpha\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"lasso_step\"))\n",
    "        self.__check_values(provided_step, min_step, max_step, default_step, \"lasso_step\")\n",
    "\n",
    "    def __polynomial(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Polynomial\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"polynomial_min_degrees\", \"polynomial_max_degrees\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"polynomial - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_degrees = 0\n",
    "        default_max_degrees = 2 # в доке sklearn это стандартное значение\n",
    "        # проверка alpha\n",
    "        min_degrees = 0\n",
    "        max_degrees = 5\n",
    "        provided_min_degrees = self.__to_list(data.get(\"polynomial_min_degrees\"))\n",
    "        self.__check_values(provided_min_degrees, min_degrees, max_degrees, default_min_degrees, \"polynomial_min_degrees\")\n",
    "        provided_max_degrees = self.__to_list(data.get(\"polynomial_max_degrees\"))\n",
    "        # проверка, чтобы max_degrees был > min_degrees\n",
    "        self.__check_values(provided_max_degrees, provided_min_degrees[0], max_degrees, default_max_degrees, \"polynomial_max_degrees\")\n",
    "\n",
    "    def __ransac(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Ransac\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"ransac_min_degrees\", \"ransac_max_degrees\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"ransac - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_degrees = 1\n",
    "        default_max_degrees = 2\n",
    "        # проверка alpha\n",
    "        min_degrees = 1\n",
    "        max_degrees = 5\n",
    "        provided_min_degrees = self.__to_list(data.get(\"ransac_min_degrees\"))\n",
    "        self.__check_values(provided_min_degrees, min_degrees, max_degrees, default_min_degrees, \"ransac_min_degrees\")\n",
    "        provided_max_degrees = self.__to_list(data.get(\"ransac_max_degrees\"))\n",
    "        # проверка, чтобы max_degrees был > min_degrees\n",
    "        self.__check_values(provided_max_degrees, provided_min_degrees[0], max_degrees, default_max_degrees, \"ransac_max_degrees\")\n",
    "\n",
    "    def __ridge(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Ridge\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"ridge_min_alpha\", \"ridge_max_alpha\", \n",
    "                            \"ridge_step\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"ridge - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_alpha = 0\n",
    "        default_max_alpha = 1\n",
    "        default_step = 0.05\n",
    "        # проверка alpha\n",
    "        min_alpha = 0\n",
    "        max_alpha = 5 # в документации sklearn до бесконечности \n",
    "        provided_min_alpha = self.__to_list(data.get(\"ridge_min_alpha\"))\n",
    "        self.__check_values(provided_min_alpha, min_alpha, max_alpha, default_min_alpha, \"ridge_min_alpha\")\n",
    "        provided_max_alpha = self.__to_list(data.get(\"ridge_max_alpha\"))\n",
    "        # проверка, чтобы max_alpha был > min_alpha\n",
    "        self.__check_values(provided_max_alpha, provided_min_alpha[0], max_alpha, default_max_alpha, \"ridge_max_alpha\")\n",
    "        # проверка step\n",
    "        min_step = 0\n",
    "        max_step = 1\n",
    "        provided_step = self.__to_list(data.get(\"ridge_step\"))\n",
    "        self.__check_values(provided_step, min_step, max_step, default_step, \"ridge_step\")\n",
    "\n",
    "    def __rol_mean(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Rol Mean\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"rol_mean_min_window_size\", \"rol_mean_max_window_size\", \n",
    "                            \"rol_mean_weights_type\", \"rol_mean_weights_coeffs\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"rol_mean - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_window_size = 1\n",
    "        default_max_window_size = 10\n",
    "        default_weights_coeffs = 2\n",
    "        # проверка window size\n",
    "        min_window_size = 1\n",
    "        max_windows_size = 10 \n",
    "        provided_min_window_size = self.__to_list(data.get(\"rol_mean_min_window_size\"))\n",
    "        self.__check_values(provided_min_window_size, min_window_size, max_windows_size, \n",
    "                            default_min_window_size, \"rol_mean_min_window_size\")\n",
    "        provided_max_window_size = self.__to_list(data.get(\"rol_mean_max_window_size\"))\n",
    "        # проверка, чтобы max_window_size был > min_window_size\n",
    "        self.__check_values(provided_max_window_size, provided_min_window_size[0], \n",
    "                            max_windows_size, default_max_window_size,\n",
    "                            \"rol_mean_max_window_size\")\n",
    "        # проверка weight_coeffs\n",
    "        min_weight_coeffs = 0\n",
    "        max_weight_coeffs = 10 # поменять значение после ресерча\n",
    "        provided_weight_coeffs = self.__to_list(data.get(\"rol_mean_weights_coeffs\"))\n",
    "        self.__check_values(provided_weight_coeffs, min_weight_coeffs, max_weight_coeffs, \n",
    "                            default_weights_coeffs, \"rol_mean_weights_coeffs\")\n",
    "        # проверка weights_type\n",
    "        try:\n",
    "            default_weights_type = [\"new\"]\n",
    "            provided_weigths_type = self.__to_list(data.get(\"rol_mean_weights_type\"))\n",
    "            # здесь необходимо определить логику - какие есть допустимые значения и на что заменять в случае несоответствия\n",
    "            self.__check_list_is_subset(default_weights_type, provided_weigths_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"rol_mean_weights_type - {e}\")\n",
    "\n",
    "    def __theil_sen(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Theil Sen\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"theil_sen_min_degrees\", \"theil_sen_max_degrees\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"theil_sen - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_degrees = 1\n",
    "        default_max_degrees = 3\n",
    "        # проверка alpha\n",
    "        min_degrees = 1\n",
    "        max_degrees = 5\n",
    "        provided_min_degrees = self.__to_list(data.get(\"theil_sen_min_degrees\"))\n",
    "        self.__check_values(provided_min_degrees, min_degrees, max_degrees, \n",
    "                            default_min_degrees, \"theil_sen_min_degrees\")\n",
    "        provided_max_degrees = self.__to_list(data.get(\"theil_sen_max_degrees\"))\n",
    "        # проверка, чтобы max_degrees был > min_degrees\n",
    "        self.__check_values(provided_max_degrees, provided_min_degrees[0], max_degrees, \n",
    "                            default_max_degrees, \"theil_sen_max_degrees\")\n",
    "\n",
    "    def __const(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Const\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"type\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"const - {e}\")\n",
    "        try:\n",
    "            # проверка weights_type\n",
    "            default_type = [\"Median\"]\n",
    "            provided_type = self.__to_list(data.get(\"type\"))\n",
    "            # здесь необходимо определить логику - какие есть допустимые значения и на что заменять в случае несоответствия\n",
    "            self.__check_list_is_subset(default_type, provided_type)\n",
    "        except ValueError as e:\n",
    "            print(f\"const_type - {e}\")\n",
    "  \n",
    "    def __sarima(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Sarima\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"min_p\", \"max_p\", \"min_d\", \"max_d\", \"min_q\",\n",
    "                            \"max_q\", \"min_P\", \"max_P\", \"min_D\", \"max_D\",\n",
    "                            \"min_Q\", \"max_Q\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"sarima - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_p = 0\n",
    "        default_max_p = 1\n",
    "        default_min_d = 0\n",
    "        default_max_d = 1\n",
    "        default_min_q = 0\n",
    "        default_max_q = 1\n",
    "        default_min_P = 0\n",
    "        default_max_P = 1\n",
    "        default_min_D = 0\n",
    "        default_max_D = 1\n",
    "        default_min_Q = 0\n",
    "        default_max_Q = 1\n",
    "        # проверка p\n",
    "        min_p = 0\n",
    "        max_p = 1\n",
    "        provided_min_p = self.__to_list(data.get(\"min_p\"))\n",
    "        self.__check_values(provided_min_p, min_p, max_p, default_min_p, \"min_p\")\n",
    "        provided_max_p = self.__to_list(data.get(\"max_p\"))\n",
    "        # проверка, чтобы max_p был > min_p\n",
    "        self.__check_values(provided_max_p, provided_min_p[0], max_p, default_max_p, \"max_p\")\n",
    "        # проверка d\n",
    "        min_d = 0\n",
    "        max_d = 1\n",
    "        provided_min_d = self.__to_list(data.get(\"min_d\"))\n",
    "        self.__check_values(provided_min_d, min_d, max_d, default_min_d, \"min_d\")\n",
    "        provided_max_d = self.__to_list(data.get(\"max_d\"))\n",
    "        # проверка, чтобы max_d был > min_d\n",
    "        self.__check_values(provided_max_d, provided_min_d[0], max_d, default_max_d, \"max_d\")\n",
    "        # проверка q\n",
    "        min_q = 0\n",
    "        max_q = 1\n",
    "        provided_min_q = self.__to_list(data.get(\"min_q\"))\n",
    "        self.__check_values(provided_min_q, min_q, max_q, default_min_q, \"min_q\")\n",
    "        provided_max_q = self.__to_list(data.get(\"max_q\"))\n",
    "        # проверка, чтобы max_q был > min_q\n",
    "        self.__check_values(provided_max_q, provided_min_q[0], max_q, default_max_q, \"max_q\")\n",
    "        # проверка P\n",
    "        min_P = 0\n",
    "        max_P = 1\n",
    "        provided_min_P = self.__to_list(data.get(\"min_P\"))\n",
    "        self.__check_values(provided_min_P, min_P, max_P, default_min_P, \"min_P\")\n",
    "        provided_max_P = self.__to_list(data.get(\"max_P\"))\n",
    "        # проверка, чтобы max_P был > min_P\n",
    "        self.__check_values(provided_max_P, provided_min_P[0], max_P, default_max_P, \"max_P\")\n",
    "        # проверка D\n",
    "        min_D = 0\n",
    "        max_D = 1\n",
    "        provided_min_D = self.__to_list(data.get(\"min_D\"))\n",
    "        self.__check_values(provided_min_D, min_D, max_D, default_min_D, \"min_D\")\n",
    "        provided_max_D = self.__to_list(data.get(\"max_D\"))\n",
    "        # проверка, чтобы max_D был > min_D\n",
    "        self.__check_values(provided_max_D, provided_min_D[0], max_D, default_max_D, \"max_D\")\n",
    "        # проверка Q\n",
    "        min_Q = 0\n",
    "        max_Q = 1\n",
    "        provided_min_Q = self.__to_list(data.get(\"min_Q\"))\n",
    "        self.__check_values(provided_min_Q, min_Q, max_Q, default_min_Q, \"min_Q\")\n",
    "        provided_max_Q = self.__to_list(data.get(\"max_Q\"))\n",
    "        # проверка, чтобы max_Q был > min_Q\n",
    "        self.__check_values(provided_max_Q, provided_min_Q[0], max_Q, default_max_Q, \"max_Q\")\n",
    "\n",
    "    def __prophet(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Prophet\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"seasonality_mode\", \"changepoint_prior_scale\", \n",
    "                            \"seasonality_prior_scale\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"prophet - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_changepoint_prior_scale = 0.05\n",
    "        default_seasonality_prior_scale = 5\n",
    "        # проверка changepoint_prior_scale\n",
    "        min_changepoint_prior_scale = 0.000001\n",
    "        max_changepoint_prior_scale = 0.7\n",
    "        provided_changepoint_prior_scale = self.__to_list(data.get(\"changepoint_prior_scale\"))\n",
    "        self.__check_values(provided_changepoint_prior_scale, min_changepoint_prior_scale, \n",
    "                            max_changepoint_prior_scale, default_changepoint_prior_scale, \n",
    "                            \"changepoint_prior_scale\")\n",
    "        # проверка seasonality_prior_scale\n",
    "        min_seasonality_prior_scale = 0.000001\n",
    "        max_seasonality_prior_scale = 100\n",
    "        provided_seasonality_prior_scale = self.__to_list(data.get(\"seasonality_prior_scale\"))\n",
    "        self.__check_values(provided_seasonality_prior_scale, min_seasonality_prior_scale, \n",
    "                            max_seasonality_prior_scale, default_seasonality_prior_scale,\n",
    "                            \"seasonality_prior_scale\")\n",
    "        # проверка seasonality_mode\n",
    "        default_seasonality_mode = [\"additive\",\"multiplicative\"]\n",
    "        provided_seasonality_mode = self.__to_list(data.get(\"seasonality_mode\"))\n",
    "        self.__check_list_is_subset(default_seasonality_mode, provided_seasonality_mode)\n",
    "\n",
    "    def __is_valid_max_features(self, max_features):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметра max_features в модели Random Forest\n",
    "\n",
    "        :param max_features: Значение гиперпараметра.\n",
    "        \"\"\"\n",
    "        if isinstance(max_features, int):\n",
    "            if not 0 < 1 <= max_features:\n",
    "                raise ValueError(\"Некорректное значение max_features\")\n",
    "        elif isinstance(max_features, float):\n",
    "            if not 0.0 < max_features <= 1.0:\n",
    "                raise ValueError(\"Некорректное значение max_features\")\n",
    "        elif max_features not in [\"sqrt\", \"log2\", None]:\n",
    "            raise ValueError(\"Некорректное значение max_features\")\n",
    "        \n",
    "    def __check_max_features_values(self, list: list, default_value):\n",
    "        \"\"\"\n",
    "        Метод для проверки, что элементы в списке доступны для использования в качестве\n",
    "        значения гиперпараметра max_features в модели Random Forest.\n",
    "\n",
    "        :param list: Список чисел для проверки;\n",
    "        :param default_value: Стандартное значение для замены некорректных данных.\n",
    "        \"\"\"\n",
    "        for element in list:\n",
    "            try:\n",
    "                element = self.__is_valid_max_features(element)\n",
    "            except ValueError as e:\n",
    "                print(f\"random_forest - {e}, значение заменено на {default_value}\")\n",
    "                element = default_value\n",
    "\n",
    "    def __random_forest(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Random Forest\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"max_features\", \"n_estimators\", \"max_depth\",\n",
    "                            \"min_samples_split\", \"min_samples_leaf\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"random_forest - {e}\")\n",
    "        # задаём стандартные значения из документации\n",
    "        default_max_features = 1.0 # из документации sklearn\n",
    "        default_n_estimators = 100 # из документации sklearn\n",
    "        default_max_depth = None # из документации sklearn\n",
    "        default_min_samples_split = 2 # из документации sklearn\n",
    "        default_min_samples_leaf = 1 # из документации sklearn\n",
    "        # проверка max_features\n",
    "        # возможные принимаемые значения {“sqrt”, “log2”, None}, int or float, default=1.0\n",
    "        provided_max_features = self.__to_list(data.get(\"max_features\"))\n",
    "        self.__check_max_features_values(provided_max_features, default_max_features)\n",
    "        # проверка n_estimators\n",
    "        min_n_estimators = 1\n",
    "        max_n_estimators = 100\n",
    "        provided_n_estimators = self.__to_list(data.get(\"n_estimators\"))\n",
    "        self.__check_values(provided_n_estimators, min_n_estimators, max_n_estimators, \n",
    "                                   default_n_estimators, \"n_estimators\")\n",
    "        # проверка max_depth\n",
    "        min_max_depth = 1\n",
    "        max_max_depth = 1000\n",
    "        provided_depth = self.__to_list(data.get(\"max_depth\"))\n",
    "        self.__check_values(provided_depth, min_max_depth, max_max_depth, default_max_depth, \"max_depth\")\n",
    "        # проверка min_samples_split\n",
    "        min_min_samples_split = 1\n",
    "        max_min_samples_split = 100\n",
    "        provided_min_samples_split = self.__to_list(data.get(\"min_samples_split\"))\n",
    "        self.__check_values(provided_min_samples_split, min_min_samples_split, max_min_samples_split, \n",
    "                            default_min_samples_split, \"min_samples_split\")\n",
    "        # проверка min_samples_leaf\n",
    "        min_min_samples_leaf = 1\n",
    "        max_min_samples_leaf = 100\n",
    "        provided_min_samples_leaf = self.__to_list(data.get(\"min_samples_leaf\"))\n",
    "        self.__check_values(provided_min_samples_leaf, min_min_samples_leaf, max_min_samples_leaf, \n",
    "                            default_min_samples_leaf, \"min_samples_leaf\")\n",
    "\n",
    "\n",
    "    def __catboost(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Catboost\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"learning_rate\", \"n_estimators\", \"depth\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"catboost - {e}\")\n",
    "        # задаём стандартные значения из документации\n",
    "        default_learning_rate = 0.03\n",
    "        default_n_estimators = 15 # в документации 1000, \n",
    "        # но по материалам, которые мне скинули - больше 30 не используется. Поэтому поставил среднее в 15\n",
    "        default_depth = 6\n",
    "        # проверка learning_rate\n",
    "        min_learning_rate = 0\n",
    "        max_learning_rate = 1\n",
    "        provided_learning_rate = self.__to_list(data.get(\"learning_rate\"))\n",
    "        self.__strong_check_values(provided_learning_rate, min_learning_rate, max_learning_rate, \n",
    "                                   default_learning_rate, \"learning_rate\")\n",
    "        # проверка n_estimators\n",
    "        min_n_estimators = 1\n",
    "        max_n_estimators = 50\n",
    "        provided_n_estimators = self.__to_list(data.get(\"n_estimators\"))\n",
    "        self.__check_values(provided_n_estimators, min_n_estimators, max_n_estimators, \n",
    "                                   default_n_estimators, \"n_estimators\")\n",
    "        # проверка depth\n",
    "        min_depth = 0\n",
    "        max_depth = 16\n",
    "        provided_depth = self.__to_list(data.get(\"depth\"))\n",
    "        self.__strong_check_values(provided_depth, min_depth, max_depth, default_depth, \"depth\")\n",
    "\n",
    "    def __symfit_fourier_fft(self, data: dict):\n",
    "        \"\"\"\n",
    "        Метод для проверки гиперпараметров модели Symfit Fourier FFT\n",
    "\n",
    "        :param data: Гиперпараметры модели для валидации \n",
    "        \"\"\"\n",
    "        try:\n",
    "            default_params = [\"min_components\", \"max_components\"]\n",
    "            provided_params = list(data.keys())\n",
    "            self.__check_lists_equal(default_params, provided_params)\n",
    "        except ValueError as e:\n",
    "            print(f\"symfit_fourier_fft - {e}\")\n",
    "        # задаём стандартные значения\n",
    "        default_min_components = 1\n",
    "        default_max_components = 10\n",
    "        # проверка components\n",
    "        min_components = 1\n",
    "        max_components = 20\n",
    "        provided_min_components = self.__to_list(data.get(\"min_components\"))\n",
    "        self.__check_values(provided_min_components, min_components, max_components, \n",
    "                            default_min_components, \"min_components\")\n",
    "        provided_max_components = self.__to_list(data.get(\"max_components\"))\n",
    "        # проверка, чтобы max_comppnents был > min_components\n",
    "        self.__check_values(provided_max_components, provided_min_components[0], max_components, \n",
    "                            default_max_components, \"max_components\")\n",
    "\n",
    "    def __validate_hyperparam(self, model: str, param: dict):\n",
    "        \"\"\"\n",
    "        Метод для валидации одного конкретного гиперпараметра\n",
    "\n",
    "        :param param: Словарь из одного элемента с данными конкретного запуска модели\n",
    "        \"\"\"\n",
    "        match model:\n",
    "            case 'croston_tsb':\n",
    "                self.__croston_tsb(param)\n",
    "            case 'elastic_net':\n",
    "                self.__elastic_net(param)\n",
    "            case 'exp_smoothing':\n",
    "                self.__exp_smoothing(param)\n",
    "            case 'holt':\n",
    "                self.__holt(param)\n",
    "            case 'holt_winters':\n",
    "                #self.__holt_winters(param)\n",
    "                pass\n",
    "            case 'huber':\n",
    "                self.__huber(param)\n",
    "            case 'lasso':\n",
    "                self.__lasso(param)\n",
    "            case 'polynomial':\n",
    "                self.__polynomial(param)\n",
    "            case 'ransac':\n",
    "                self.__ransac(param)\n",
    "            case 'ridge':\n",
    "                self.__ridge(param)\n",
    "            case 'rol_mean':\n",
    "                self.__rol_mean(param)\n",
    "            case 'theil_sen':\n",
    "                self.__theil_sen(param)\n",
    "            case 'const':\n",
    "                self.__const(param)\n",
    "            case 'catboost':\n",
    "                self.__catboost(param)\n",
    "            case 'sarima':\n",
    "                self.__sarima(param)\n",
    "            case 'prophet':\n",
    "                self.__prophet(param)\n",
    "            case 'random_forest':\n",
    "                self.__random_forest(param)\n",
    "            case 'symfit_fourier_fft':\n",
    "                self.__symfit_fourier_fft(param)\n",
    "            case _:\n",
    "                raise ValueError(\"Неподдерживаемая модель\")\n",
    "\n",
    "\n",
    "    def __validate_hyperparams(self):\n",
    "        \"\"\"\n",
    "        Метод для валидации списка гиперпараметров\n",
    "        \"\"\"\n",
    "        for model, params in zip(self.models, self.hyperparams):\n",
    "            try:\n",
    "                self.__validate_hyperparam(model, params)\n",
    "                print(f\"Валидация гиперпараметров для модели {model} прошла успешно\")\n",
    "            except ValueError as e:\n",
    "                print(e)\n",
    "\n",
    "    def get_validated_hyperparams(self) -> tuple[list, list]:\n",
    "        \"\"\"\n",
    "        Геттер для получения валидированных гиперпараметров.\n",
    "\n",
    "        :return: Кортеж из двух списков (models, hyperparams)\n",
    "        \"\"\"\n",
    "        self.__validate_hyperparams()\n",
    "        return self.models, self.hyperparams\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d2b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \"\"\"\n",
    "    Класс для работы с загрузкой и выгрузкой гиперпараметров моделей и самих экземпляров обученных моделей.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath: str):\n",
    "        \"\"\"\n",
    "        :param filepath: Путь до файла\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "\n",
    "    def load_hyperparams_from_optimacros(self) -> tuple[list, list]: # tested\n",
    "        \"\"\"\n",
    "        Метод для загрузки гиперпараметров, полученных от OptiMacros\n",
    "\n",
    "        :return: Список моделей и список гиперпараметров\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(self.filepath)\n",
    "            # переводим сразу из json в python-словари\n",
    "            data.loc[:, 'Params'] = data.loc[:, 'Params'].apply(json.loads)\n",
    "            models = data.loc[:, 'Models'].to_list()\n",
    "            hyperparams = []\n",
    "            for model in models:\n",
    "                model_info = data.loc[(data.Models == model), 'Params'].iloc[0]\n",
    "                hyperparams.append(model_info[model])\n",
    "            return models, hyperparams\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Такого файла не существует\")\n",
    "\n",
    "    def load_hyperparams_from_python(self) -> tuple[list, list, list]:\n",
    "        \"\"\"\n",
    "        Метод для загрузки гиперпараметров, полученных от Python\n",
    "\n",
    "        :return: Список моделей, список гиперпараметров и список версий\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = pd.read_csv(self.filepath)\n",
    "            # переводим сразу из json в python-словари\n",
    "            data.loc[:, 'Params'] = data.loc[:, 'Params'].apply(json.loads)\n",
    "            models = data.loc[:, 'Models'].to_list()\n",
    "            versions = data.loc[:, 'Version'].to_list()\n",
    "            hyperparams = []\n",
    "            for model in models:\n",
    "                model_info = data.loc[(data.Model == model), 'Params'].iloc[0]\n",
    "                hyperparams.append(model_info[model])\n",
    "            return models, hyperparams, versions\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Такого файла не существует\")\n",
    "\n",
    "    def backup_hyperparams(self, models: list, hyperparams: list) -> str: #tested\n",
    "        \"\"\"\n",
    "        Метод для резервного копирования гиперпараметров.\n",
    "\n",
    "        :param models: Список моделей;\n",
    "        :param hyperparams: Список гиперпараметрой.\n",
    "        :return: Путь до файла с резервной копией.\n",
    "        \"\"\"\n",
    "        dir_path = os.path.dirname(self.filepath)\n",
    "        file_name = os.path.basename(self.filepath)\n",
    "        current_datetime = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "        versions = [current_datetime] * len(models)\n",
    "        data = {\"Models\": models, \"Params\": hyperparams, \"Versions\": versions}\n",
    "        df = pd.DataFrame(data)\n",
    "        df.loc[:, 'Params'] = df.loc[:, 'Params'].apply(json.dumps)\n",
    "        filepath = os.path.join(dir_path, f\"{current_datetime}_back_up_{file_name}\")\n",
    "        df.to_csv(filepath)\n",
    "        return filepath\n",
    "    \n",
    "    def __save_custom_model(self, model: str, hyperparams: list):\n",
    "        \"\"\"\n",
    "        Метод для для сохранения гиперпараметров самописных моделей.\n",
    "\n",
    "        :param model: Название модели;\n",
    "        :paran hyperparams: Гипепараметры модели.\n",
    "        \"\"\"\n",
    "        current_datetime = datetime.now().strftime(\"%Y_%m_%d_%H_%M\")\n",
    "        new_data = pd.DataFrame({'Models': model, 'Params': hyperparams, 'Version': current_datetime})\n",
    "        # если файл существует и не пуст - читаем и добавляем данные\n",
    "        if os.path.exists(self.filepath) and os.path.getsize(self.filepath) > 0:\n",
    "            old_data = pd.read_csv(f\"{self.filepath}.csv\")\n",
    "            combined_data = pd.concat([old_data, new_data], ignore_index=True)\n",
    "            combined_data.to_csv(f\"{self.filepath}.csv\", index=False)\n",
    "        else:  # если файла нет или он пуст - просто сохраняем новые данные\n",
    "            new_data.to_csv(f\"{self.filepath}.csv\", index=False)\n",
    "\n",
    "    def __get_params_from_sklearn_model(self, model_name: str, model) -> dict:\n",
    "        \"\"\"\n",
    "        Метод для извлечения параметров из Sklearn моделей.\n",
    "\n",
    "        :param model_name: Название модели;\n",
    "        :param model: Экземпляр модели.\n",
    "        :return: Словарь с гиперпараметрами.\n",
    "        \"\"\"\n",
    "        params = model.get_params()\n",
    "        return {\"Model\": model_name,\n",
    "                    \"Params\": params}\n",
    "    \n",
    "    def __get_params_from_statsmodels_model(self, model_name: str, model) -> dict:\n",
    "        \"\"\"\n",
    "        Метод для извлечения параметров из Statsmodels моделей.\n",
    "\n",
    "        :param model_name: Название модели;\n",
    "        :param model: Экземпляр модели.\n",
    "        :return: Словарь с гиперпараметрами.\n",
    "        \"\"\"\n",
    "        params = model.params\n",
    "        return {\"Model\": model_name,\n",
    "                    \"Params\": params}    \n",
    "    \n",
    "    def __get_params_from_prophet_model(self, model_name: str, model) -> dict:\n",
    "        \"\"\"\n",
    "        Метод для извлечения параметров из Prophet модели.\n",
    "\n",
    "        :param model_name: Название модели;\n",
    "        :param model: Экземпляр модели.\n",
    "        :return: Словарь с гиперпараметрами.\n",
    "        \"\"\"\n",
    "        params = model.params\n",
    "        return {\"Model\": model_name,\n",
    "                    \"Params\": params}   \n",
    "\n",
    "    def get_params(self, model) -> dict:\n",
    "        \"\"\"\n",
    "        Метод для извлечения параметров из обученных экземпляров моделей.\n",
    "        Поддерживаются следующие модели:\n",
    "\n",
    "        \"RandomForestRegressor\", \"ElasticNet\", \"HuberRegressor\", \"Lasso\", \"RANSACRegressor\", \n",
    "        \"Ridge\", \"TheilSenRegressor\", \"CatBoostRegressor\", \"Holt\", \"SimpleExpSmoothing\", \n",
    "        \"ExponentialSmoothing\", \"Prophet\". \n",
    "        \n",
    "        При использовании Sklearn моделей или Prophet необходимо передавать сам экземпляр модели.\n",
    "        \n",
    "        При использовании statsmodels необходимо передавать результат model.fit(), т.е results = model.fit() - необходимо передать results.\n",
    "        \n",
    "        :param model: Экземпляр модели.\n",
    "        :return: Словарь с гиперпараметрами.\n",
    "        \"\"\"\n",
    "        if isinstance(model, RandomForestRegressor):\n",
    "            return self.__get_params_from_sklearn_model(\"RandomForestRegressor\", model)\n",
    "        elif isinstance(model, ElasticNet):\n",
    "            return self.__get_params_from_sklearn_model(\"ElasticNet\", model)\n",
    "        elif isinstance(model, HuberRegressor):\n",
    "            return self.__get_params_from_sklearn_model(\"HuberRegressor\", model)\n",
    "        elif isinstance(model, Lasso):\n",
    "            return self.__get_params_from_sklearn_model(\"Lasso\", model)\n",
    "        elif isinstance(model, RANSACRegressor):\n",
    "            return self.__get_params_from_sklearn_model(\"RANSACRegressor\", model)\n",
    "        elif isinstance(model, Ridge):\n",
    "            return self.__get_params_from_sklearn_model(\"Ridge\", model)\n",
    "        elif isinstance(model, TheilSenRegressor):\n",
    "            return self.__get_params_from_sklearn_model(\"TheilSenRegressor\", model)\n",
    "        elif isinstance(model, CatBoostRegressor):\n",
    "            return self.__get_params_from_sklearn_model(\"CatBoostRegressor\", model) # в catboost такой же метод для извлечения гиперпараметров\n",
    "        elif isinstance(model, Holt):\n",
    "            return self.__get_params_from_statsmodels_model(\"Holt\", model)\n",
    "        elif isinstance(model, SimpleExpSmoothing):\n",
    "            return self.__get_params_from_statsmodels_model(\"ExpSmoothing\", model)\n",
    "        elif isinstance(model, ExponentialSmoothing):\n",
    "            return self.__get_params_from_statsmodels_model(\"HoltWinters\", model)\n",
    "        elif isinstance(model, Prophet):\n",
    "            return self.__get_params_from_prophet_model(\"Prophet\", model)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемая модель\")\n",
    "\n",
    "\n",
    "    def save_trained_model(self, model, filepath: str):\n",
    "        \"\"\"\n",
    "        Метод для сохранения обученной модели. В зависимости от модели \n",
    "        сохраняет либо саму модель, либо только её гиперпараметры. Если передаются гиперпараметры модели, необходимо\n",
    "        передавать словарь вида {\"model_name\": [hyperparams]}. Если передаётся сама модель, то необходимо передавать сам объект.\n",
    "        :param model: Обученная модель;\n",
    "        :param filepath: Путь до файла. Возможна дозапись в конец файла. Не указывать расширение файла - оно будет выбрано автоматически.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        custom_models = [\"croston_tsb\", \"rol_mean\", \"const\", \"symfit_fourier_fft\", \"random_forest\", \n",
    "                         \"elastic_net\", \"huber\", \"lasso\", \"ransac\", \n",
    "                         \"ridge\", \"theil_sen\", \"catboost\", \n",
    "                         \"holt\", \"exp_smoothing\", \"holt_winters\", \n",
    "                         \"sarima\", \"prophet\", \"polynomial\"]\n",
    "        if isinstance(model, dict):\n",
    "            model_name = list(model.keys())[0] # т.к возвращается итерируемый объект\n",
    "            params = list(model.values())[0]\n",
    "            if model_name in custom_models:\n",
    "                self.__save_custom_model(model_name, params)\n",
    "            else:\n",
    "                raise ValueError(\"Неподдерживаемая модель\")\n",
    "        elif isinstance(model, RandomForestRegressor):\n",
    "            joblib.dump(model, f\"RandomForestRegressor_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, ElasticNet):\n",
    "            joblib.dump(model, f\"ElasticNet_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, HuberRegressor):\n",
    "            joblib.dump(model, f\"HuberRegressor_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, Lasso):\n",
    "            joblib.dump(model, f\"Lasso_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, RANSACRegressor):\n",
    "            joblib.dump(model, f\"RANSACRegressor_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, Ridge):\n",
    "            joblib.dump(model, f\"Ridge_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, TheilSenRegressor):\n",
    "            joblib.dump(model, f\"TheilSenRegressor_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, CatBoostRegressor):\n",
    "            model.save_model(f\"CatBoostRegressor_{self.filepath}\", foramt=\"cbm\")\n",
    "        elif isinstance(model, Holt):\n",
    "            joblib.dump(model, f\"Holt_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, SimpleExpSmoothing):\n",
    "            joblib.dump(model, f\"SimpleExpSmoothing_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, ExponentialSmoothing):\n",
    "            joblib.dump(model, f\"ExponentialSmoothing_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, SARIMAX):\n",
    "            joblib.dump(model, f\"SARIMAX_{self.filepath}.joblib\")\n",
    "        elif isinstance(model, Prophet):\n",
    "            with open(f'Prophet_{self.filepath}.json', 'w') as fout:\n",
    "                fout.write(model_to_json(model))\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемая модель\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b43218",
   "metadata": {},
   "source": [
    "Пример загрузки и обработки корректных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f324542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Валидация гиперпараметров для модели croston_tsb прошла успешно\n",
      "Валидация гиперпараметров для модели elastic_net прошла успешно\n",
      "Валидация гиперпараметров для модели exp_smoothing прошла успешно\n",
      "Валидация гиперпараметров для модели holt прошла успешно\n",
      "Валидация гиперпараметров для модели holt_winters прошла успешно\n",
      "Валидация гиперпараметров для модели huber прошла успешно\n",
      "Валидация гиперпараметров для модели lasso прошла успешно\n",
      "Валидация гиперпараметров для модели polynomial прошла успешно\n",
      "Валидация гиперпараметров для модели ransac прошла успешно\n",
      "Валидация гиперпараметров для модели ridge прошла успешно\n",
      "Валидация гиперпараметров для модели rol_mean прошла успешно\n",
      "Валидация гиперпараметров для модели theil_sen прошла успешно\n",
      "Валидация гиперпараметров для модели const прошла успешно\n",
      "Валидация гиперпараметров для модели catboost прошла успешно\n",
      "Валидация гиперпараметров для модели sarima прошла успешно\n",
      "Валидация гиперпараметров для модели prophet прошла успешно\n",
      "Валидация гиперпараметров для модели random_forest прошла успешно\n",
      "Валидация гиперпараметров для модели symfit_fourier_fft прошла успешно\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025_06_28_12_21_back_up_om_correct.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(\"om_correct.csv\")\n",
    "models, hyperparams = dataloader.load_hyperparams_from_optimacros()\n",
    "validator = Validation(models, hyperparams)\n",
    "validated_data = validator.get_validated_hyperparams()\n",
    "dataloader.backup_hyperparams(validated_data[0], validated_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a546f4",
   "metadata": {},
   "source": [
    "Пример загрузки и обработки некорректных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9cb613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croston_tsb_min_alpha - некорректное значение -1, заменено на 0\n",
      "croston_tsb_max_alpha - некорректное значение 100, заменено на 1\n",
      "croston_tsb_min_beta - некорректное значение 100, заменено на 0\n",
      "croston_tsb_max_beta - некорректное значение -50, заменено на 1\n",
      "croston_tsb_step - некорректное значение 1.5, заменено на 0.1\n",
      "Валидация гиперпараметров для модели croston_tsb прошла успешно\n",
      "elastic_net_min_alpha - некорректное значение -1, заменено на 0\n",
      "elastic_net_max_alpha - некорректное значение 100, заменено на 1\n",
      "elastic_net_min_l1 - некорректное значение -1, заменено на 0\n",
      "elastic_net_max_l1 - некорректное значение 100, заменено на 1\n",
      "Валидация гиперпараметров для модели elastic_net прошла успешно\n",
      "exp_smoothing_max_alpha - некорректное значение 0, заменено на 1\n",
      "Валидация гиперпараметров для модели exp_smoothing прошла успешно\n",
      "Валидация гиперпараметров для модели holt прошла успешно\n",
      "Валидация гиперпараметров для модели holt_winters прошла успешно\n",
      "Валидация гиперпараметров для модели huber прошла успешно\n",
      "Валидация гиперпараметров для модели lasso прошла успешно\n",
      "Валидация гиперпараметров для модели polynomial прошла успешно\n",
      "Валидация гиперпараметров для модели ransac прошла успешно\n",
      "Валидация гиперпараметров для модели ridge прошла успешно\n",
      "rol_mean_weights_type - В списке находятся недопустимые значения\n",
      "Валидация гиперпараметров для модели rol_mean прошла успешно\n",
      "Валидация гиперпараметров для модели theil_sen прошла успешно\n",
      "Валидация гиперпараметров для модели const прошла успешно\n",
      "learning_rate - некорректное значение 20, заменено на 0.03\n",
      "Валидация гиперпараметров для модели catboost прошла успешно\n",
      "Валидация гиперпараметров для модели sarima прошла успешно\n",
      "Валидация гиперпараметров для модели prophet прошла успешно\n",
      "Валидация гиперпараметров для модели random_forest прошла успешно\n",
      "Валидация гиперпараметров для модели symfit_fourier_fft прошла успешно\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2025_06_28_12_21_back_up_om_incorrect.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(\"om_incorrect.csv\")\n",
    "models, hyperparams = dataloader.load_hyperparams_from_optimacros()\n",
    "validator = Validation(models, hyperparams)\n",
    "validated_data = validator.get_validated_hyperparams()\n",
    "dataloader.backup_hyperparams(validated_data[0], validated_data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
